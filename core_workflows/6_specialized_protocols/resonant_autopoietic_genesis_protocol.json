{
  "name": "Resonant Autopoietic Genesis Protocol (v3.5-GP)",
  "version": "3.5-GP",
  "description": "SPR-aware genesis workflow that parses the canonical ResonantiA Protocol v3.5-GP, recognizes/activates SPRs, proposes module blueprints with orchestrator contracts, and compiles a comprehensive genesis report aligned with Critical Mandates.",
  "expects_initial_context": {
    "protocol_path": "ResonantiA_Protocol_v3.5-GP_Canonical.md",
    "target_output_root": "Directory root for generated code (e.g., Four_PointO_ArchE/ or arche_genesis/)",
    "spr_definitions_path": "Optional path to knowledge_graph/spr_definitions_tv.json (defaults to knowledge_graph/spr_definitions_tv.json)",
    "author": "Optional author/Keyholder name for report headers",
    "include_orchestrators": "Include ACO, RISE, and Autonomous Orchestrator contracts (default: true)",
    "include_critical_mandates": "Include 12 Critical Mandates integration (default: true)",
    "include_operational_recipes": "Include SIRC, Metacognitive shifT, Insight Solidification, Phoenix (default: true)"
  },
  "tasks": {
    "ingest_canonical_specification": {
      "description": "Read the canonical protocol document and extract text, headings, and integrity hash.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import json,hashlib,os,re\npath = '{{initial_context.protocol_path | default('ResonantiA_Protocol_v3.5-GP_Canonical.md')}}'\nres={'error':None,'spec_text':None,'headings':[],'sha256':None,'path_used':path}\ntry:\n    with open(path,'r',encoding='utf-8',errors='replace') as f:\n        txt=f.read()\n    res['spec_text']=txt\n    res['sha256']=hashlib.sha256(txt.encode('utf-8')).hexdigest()\n    heads=[]\n    for line in txt.splitlines():\n        m=re.match(r'^(#{1,4})\\s+(.*)$',line)\n        if m:\n            level=len(m.group(1)); title=m.group(2).strip(); heads.append({'level':level,'title':title})\n    res['headings']=heads\nexcept Exception as e:\n    res['error']=str(e)\nprint(json.dumps(res))"
      },
      "outputs": {
        "spec_text": "string",
        "headings": "list",
        "sha256": "string",
        "path_used": "string",
        "error": "string"
      },
      "dependencies": []
    },

    "deconstruct_and_recognize_sprs": {
      "description": "Identify likely SPR tokens (Guardian-points format) from the v3.5-GP spec text, including orchestrators, tools, and Critical Mandates; summarize by section.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "You detect Sparse Priming Representations (SPRs) in ResonantiA Protocol v3.5-GP text. SPRs have Guardian-points formatting: first and last characters uppercase or digit; interior characters lowercase or spaces; avoid all-caps >3. Focus on: Orchestrators (ACO, RISE, Autonomous), Tools (Code executoR, Causal InferencE, ABM, PredictivE ModelinG, etc.), Critical Mandates (Crucible, Proactive Truth Resonance, etc.), and Core Concepts (Cognitive resonancE, Temporal resonancE, Implementation resonancE, etc.). Output comprehensive JSON with found_sprs (deduped in order), spr_counts, mentions_by_section, and spr_categories (orchestrators, tools, mandates, concepts).",
        "prompt": "Protocol Headings (JSON):\n```json\n{{ingest_canonical_specification.result.result.headings}}\n```\n\nProtocol Text (truncated if large):\n```\n{{ingest_canonical_specification.result.result.spec_text}}\n```\n\nFocus on identifying:\n- Orchestrators: ACO, RISE, Autonomous Orchestrator\n- Core Tools: Code executoR, Causal InferencE, Agent Based ModelinG, PredictivE ModelinG, LLMTooL, WebSearcH, CFP\n- Critical Mandates: Crucible, Proactive Truth Resonance, Cognitive Tools Actuation, etc.\n- Core Concepts: Cognitive resonancE, Temporal resonancE, Implementation resonancE, Knowledge network onenesS, Sparse priming representationS\n- Operational Recipes: SIRC, Metacognitive shifT, Insight Solidification, Phoenix\n\nReturn a JSON object with keys: found_sprs (list), spr_counts (object), mentions_by_section (object), spr_categories (object with orchestrators, tools, mandates, concepts, recipes).",
        "max_tokens": 1500,
        "temperature": 0.2
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["ingest_canonical_specification", "safety_gate_check"],
      "condition": "{{ ingest_canonical_specification.result.result.error == null }}"
    },

    "load_spr_knowledge_graph": {
      "description": "Load the knowledge graph SPR definitions for cross-reference.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import json,os\npath = '{{initial_context.spr_definitions_path | default('knowledge_graph/spr_definitions_tv.json')}}'\nres={'error':None,'path_used':path,'spr_kg':None}\ntry:\n    if os.path.exists(path):\n        with open(path,'r',encoding='utf-8',errors='replace') as f:\n            res['spr_kg']=json.load(f)\n    else:\n        res['error']=f'Not found: {path}'\nexcept Exception as e:\n    res['error']=str(e)\nprint(json.dumps(res))"
      },
      "outputs": {
        "spr_kg": "any",
        "path_used": "string",
        "error": "string"
      },
      "dependencies": []
    },

    "analyze_existing_architecture": {
      "description": "Analyze existing Four_PointO_ArchE v4.0 structure to ensure proper integration with v3.5-GP components and create safety backup.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import os, json, shutil, hashlib, datetime\nfrom pathlib import Path\n\n# Analyze Four_PointO_ArchE structure with safety measures\ntarget_root = '{{initial_context.target_output_root | default('Four_PointO_ArchE')}}'\n# Ensure target_root doesn't end with slash for proper backup naming\nif target_root.endswith('/'):\n    target_root = target_root[:-1]\nbackup_root = f'{target_root}_backup_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\nres = {'error': None, 'architecture_analysis': {}, 'existing_modules': [], 'integration_points': [], 'safety_measures': {}, 'backup_created': False}\n\ntry:\n    # Check if target directory exists\n    if not os.path.exists(target_root):\n        res['error'] = f'Target directory {target_root} does not exist'\n        print(json.dumps(res))\n        exit()\n    \n    # SAFETY: Create backup before any modifications\n    print(f'SAFETY: Creating backup at {backup_root}')\n    shutil.copytree(target_root, backup_root, ignore=shutil.ignore_patterns('__pycache__', '*.pyc', '.git'))\n    res['backup_created'] = True\n    res['backup_location'] = backup_root\n    \n    # Create safety manifest\n    safety_manifest = {\n        'backup_created': datetime.datetime.now().isoformat(),\n        'original_path': target_root,\n        'backup_path': backup_root,\n        'safety_version': '1.0',\n        'critical_files': []\n    }\n    \n    # Analyze existing structure\n    tools_dir = os.path.join(target_root, 'tools')\n    workflow_dir = os.path.join(target_root, 'workflow')\n    knowledge_dir = os.path.join(target_root, 'knowledge_graph')\n    tsp_dir = os.path.join(target_root, 'tsp_solver')\n    \n    # Check existing modules and create file hashes for integrity\n    existing_modules = []\n    critical_files = []\n    \n    if os.path.exists(tools_dir):\n        for file in os.listdir(tools_dir):\n            if file.endswith('.py') and not file.startswith('__'):\n                file_path = os.path.join(tools_dir, file)\n                existing_modules.append(f'tools/{file}')\n                # Create hash for integrity checking\n                with open(file_path, 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                critical_files.append({\n                    'path': f'tools/{file}',\n                    'hash': file_hash,\n                    'size': os.path.getsize(file_path),\n                    'modified': os.path.getmtime(file_path)\n                })\n    \n    if os.path.exists(workflow_dir):\n        for file in os.listdir(workflow_dir):\n            if file.endswith('.py') and not file.startswith('__'):\n                file_path = os.path.join(workflow_dir, file)\n                existing_modules.append(f'workflow/{file}')\n                with open(file_path, 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                critical_files.append({\n                    'path': f'workflow/{file}',\n                    'hash': file_hash,\n                    'size': os.path.getsize(file_path),\n                    'modified': os.path.getmtime(file_path)\n                })\n    \n    # Check knowledge graph structure\n    knowledge_files = []\n    if os.path.exists(knowledge_dir):\n        for file in os.listdir(knowledge_dir):\n            if file.endswith('.json'):\n                file_path = os.path.join(knowledge_dir, file)\n                knowledge_files.append(f'knowledge_graph/{file}')\n                with open(file_path, 'rb') as f:\n                    file_hash = hashlib.sha256(f.read()).hexdigest()\n                critical_files.append({\n                    'path': f'knowledge_graph/{file}',\n                    'hash': file_hash,\n                    'size': os.path.getsize(file_path),\n                    'modified': os.path.getmtime(file_path)\n                })\n    \n    # Integration points for v3.5-GP with safety considerations\n    integration_points = [\n        'tools/action_registry.py - extend with new orchestrator actions (SAFE: backup created)',\n        'workflow/engine.py - add orchestrator contract support (SAFE: backup created)',\n        'knowledge_graph/ - add SPR definitions and protocol events (SAFE: new files only)',\n        'tools/ - add new orchestrator modules (ACO, RISE, Autonomous) (SAFE: new files only)',\n        'tools/ - add Critical Mandates integration modules (SAFE: new files only)'\n    ]\n    \n    # Safety measures\n    safety_measures = {\n        'backup_created': True,\n        'backup_location': backup_root,\n        'critical_files_protected': len(critical_files),\n        'file_integrity_hashes': critical_files,\n        'rollback_available': True,\n        'modification_strategy': 'enhance_existing_with_backup',\n        'new_files_only': True\n    }\n    \n    # Save safety manifest\n    safety_manifest['critical_files'] = critical_files\n    safety_manifest_path = os.path.join(backup_root, 'safety_manifest.json')\n    with open(safety_manifest_path, 'w') as f:\n        json.dump(safety_manifest, f, indent=2)\n    \n    res['architecture_analysis'] = {\n        'version': '4.0',\n        'structure': {\n            'tools_dir': os.path.exists(tools_dir),\n            'workflow_dir': os.path.exists(workflow_dir),\n            'knowledge_dir': os.path.exists(knowledge_dir),\n            'tsp_dir': os.path.exists(tsp_dir)\n        },\n        'existing_modules': existing_modules,\n        'knowledge_files': knowledge_files,\n        'integration_points': integration_points\n    }\n    \n    res['safety_measures'] = safety_measures\n    \nexcept Exception as e:\n    res['error'] = str(e)\n    res['backup_created'] = False\n\nprint(json.dumps(res))"
      },
      "outputs": {
        "architecture_analysis": "any",
        "existing_modules": "list",
        "integration_points": "list",
        "safety_measures": "any",
        "backup_created": "boolean",
        "backup_location": "string",
        "error": "string"
      },
      "dependencies": []
    },

    "cross_reference_knowledge_graph": {
      "description": "Cross-reference recognized SPRs with the knowledge graph to gather definitions and blueprint hints.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "You map a list of SPR ids to knowledge graph entries. The KG may be a list of objects (with spr_id) or a dict keyed by spr_id. Return JSON with resolved_sprs (spr_id, definition, category, relationships, blueprint_details) and unresolved_sprs (list).",
        "prompt": "Found SPRs (JSON):\n```json\n{{deconstruct_and_recognize_sprs.response_text}}\n```\n\nSPR Knowledge Graph (may be large):\n```json\n{{load_spr_knowledge_graph.result.result.spr_kg}}\n```\n\nProduce a JSON with: resolved_sprs (list of objects), unresolved_sprs (list).",
        "max_tokens": 1000,
        "temperature": 0.2
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["deconstruct_and_recognize_sprs", "load_spr_knowledge_graph"],
      "condition": "{{ load_spr_knowledge_graph.result.result.error == null }}"
    },

    "compute_activation_map": {
      "description": "Transform SPRs + KG into an activation map: modules, files, responsibilities for codegen, including orchestrator contracts and Critical Mandates integration, aligned with Four_PointO_ArchE v4.0 structure.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Create a comprehensive activation map from v3.5-GP SPRs aligned with Four_PointO_ArchE v4.0 structure: list modules, their target files, and responsibilities. Include core modules (workflow_engine, action_registry, spr_manager), orchestrator contracts (ACO, RISE, Autonomous), tool implementations (cfp_framework, code_executor, predictive_modeling, causal_inference, abm), and Critical Mandates integration. Ensure IAR compliance and phase-gate enforcement throughout. Consider existing architecture and integration points.",
        "prompt": "Resolved SPRs (JSON):\n```json\n{{cross_reference_knowledge_graph.response_text}}\n```\n\nExisting Architecture Analysis:\n```json\n{{analyze_existing_architecture.result.result.architecture_analysis}}\n```\n\nIntegration Points:\n{{analyze_existing_architecture.result.result.integration_points}}\n\nInclude orchestrator contracts:\n- ACO (Adaptive Cognitive Orchestrator): pattern evolution, emergent domain detection, controller generation\n- RISE Orchestrator: deep insight generation, strategic synthesis, hypothesis planning\n- Autonomous Orchestrator: work management, task prioritization, escalation gates\n\nInclude Critical Mandates integration:\n- Crucible (Live Validation)\n- Proactive Truth Resonance\n- Cognitive Tools Actuation\n- Implementation resonancE\n- Temporal resonancE\n- Guardian (Security & Override)\n- Crystal (Knowledge Evolution)\n- Visionary (Complex System Visioning)\n- Heartbeat (Workflow EnginE)\n- Phoenix (Autonomous Evolution)\n- Utopian (Synergistic Fusion)\n\nAlign with Four_PointO_ArchE v4.0 structure:\n- tools/ directory for new orchestrator modules\n- workflow/ directory for enhanced workflow engine\n- knowledge_graph/ directory for SPR definitions and protocol events\n- Maintain existing action_registry.py patterns\n- Follow existing perception_orchestrator.py patterns\n\nReturn JSON: {\n  'modules': [\n    { 'module': 'workflow_engine', 'files': ['workflow/engine.py'], 'sprs': ['...'], 'responsibilities': ['...'], 'mandates': ['...'], 'orchestrator_type': 'core', 'integration_type': 'enhance_existing' },\n    { 'module': 'action_registry', 'files': ['tools/action_registry.py'], 'sprs': ['Action registrY'], 'responsibilities': ['action management'], 'mandates': ['Cognitive Tools Actuation'], 'orchestrator_type': 'core', 'integration_type': 'enhance_existing' },\n    { 'module': 'adaptive_cognitive_orchestrator', 'files': ['tools/adaptive_cognitive_orchestrator.py'], 'sprs': ['ACO', 'Pattern EvolutioN'], 'responsibilities': ['pattern analysis', 'controller generation'], 'mandates': ['Phoenix'], 'orchestrator_type': 'ACO', 'integration_type': 'new_module' },\n    { 'module': 'rise_orchestrator', 'files': ['tools/rise_orchestrator.py'], 'sprs': ['RISE', 'Deep Insight GeneratioN'], 'responsibilities': ['strategic synthesis', 'hypothesis planning'], 'mandates': ['Visionary'], 'orchestrator_type': 'RISE', 'integration_type': 'new_module' },\n    { 'module': 'autonomous_orchestrator', 'files': ['tools/autonomous_orchestrator.py'], 'sprs': ['Autonomous OrchestratioN', 'Work ManagemenT'], 'responsibilities': ['task prioritization', 'escalation management'], 'mandates': ['Phoenix', 'Utopian'], 'orchestrator_type': 'Autonomous', 'integration_type': 'new_module' },\n    ...\n  ],\n  'orchestrator_contracts': {\n    'ACO': { 'purpose': 'pattern evolution', 'inputs': ['context', 'recent_iars'], 'outputs': ['controller_update'] },\n    'RISE': { 'purpose': 'deep synthesis', 'inputs': ['problem_statement', 'evidence_pack'], 'outputs': ['insight_plan'] },\n    'Autonomous': { 'purpose': 'work management', 'inputs': ['controller_update', 'impact_forecast'], 'outputs': ['rollout_decision'] }\n  },\n  'integration_strategy': {\n    'enhance_existing': ['workflow/engine.py', 'tools/action_registry.py'],\n    'new_modules': ['tools/adaptive_cognitive_orchestrator.py', 'tools/rise_orchestrator.py', 'tools/autonomous_orchestrator.py'],\n    'knowledge_graph_updates': ['spr_definitions_tv.json', 'protocol_events.json']\n  }\n}",
        "max_tokens": 3600,
        "temperature": 0.25
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["cross_reference_knowledge_graph", "analyze_existing_architecture"]
    },

    "generate_module_blueprints": {
      "description": "Produce code-level blueprints (classes, functions, interfaces) for each module in the activation map, including Critical Mandates integration and orchestrator contracts.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Generate comprehensive, production-oriented Python module blueprints aligned to v3.5-GP activation map. Include file names, public classes/functions with signatures and docstrings, key responsibilities, extension points, and Critical Mandates integration. Emphasize IAR-compliant return dicts, phase-gate enforcement, and orchestrator contract compliance.",
        "prompt": "Activation Map (JSON):\n```json\n{{compute_activation_map.response_text}}\n```\n\nConstraints:\n- Target output root: {{initial_context.target_output_root | default('Four_PointO_ArchE/')}}\n- Conform to ResonantiA Protocol v3.5-GP semantics\n- Align with existing Four_PointO_ArchE v4.0 structure and patterns\n- Follow existing code patterns: action_registry.py, perception_orchestrator.py, workflow/engine.py\n- Include Critical Mandates integration in each module\n- Implement orchestrator contracts (ACO, RISE, Autonomous) as new modules\n- Ensure IAR compliance and phase-gate enforcement\n- Include Protocol Event Schema compliance\n- Maintain existing knowledge_graph/ structure for perception targets\n- Follow existing tool structure in tools/ directory\n- For each file, outline APIs, docstrings, and mandate integration. \n- **CRITICAL**: Under no circumstances should you ever use placeholder text like '... existing code ...', '# ... existing code ...', or any variation. The generated code must be complete, fully functional, and ready for execution.\n\nExisting Four_PointO_ArchE Structure:\n- tools/action_registry.py: Canonical action registry with execute_web_task\n- tools/perception_orchestrator.py: Web interaction orchestrator\n- workflow/engine.py: Workflow execution engine with native capabilities\n- knowledge_graph/perception_targets.json: Web interaction targets\n- tsp_solver/: Native TSP solving capabilities\n\nCritical Mandates to integrate:\n1. Crucible (Live Validation)\n2. Proactive Truth Resonance\n3. Cognitive Tools Actuation\n4. Collective Intelligence\n5. Implementation resonancE\n6. Temporal resonancE\n7. Guardian (Security & Override)\n8. Crystal (Knowledge Evolution)\n9. Visionary (Complex System Visioning)\n10. Heartbeat (Workflow EnginE)\n11. Phoenix (Autonomous Evolution)\n12. Utopian (Synergistic Fusion)",
        "max_tokens": 50000,
        "temperature": 0.35
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["compute_activation_map", "safety_gate_check"],
              "condition": "{{ safety_gate_check.result.result.safety_gate_passed == true }}"
    },

    "generate_operational_recipes": {
      "description": "Generate operational recipe implementations for SIRC, Metacognitive shifT, Insight Solidification, and Phoenix based on v3.5-GP specifications.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Generate comprehensive operational recipe implementations for ResonantiA Protocol v3.5-GP. Create detailed Python implementations for SIRC (Synergistic Intent Resonance Cycle), Metacognitive shifT, Insight Solidification, and Phoenix (Autonomous Evolution) recipes. Include IAR compliance, phase-gate enforcement, and integration with orchestrator contracts.",
        "prompt": "Protocol Text (for recipe context):\n```\n{{ingest_canonical_specification.result.result.spec_text}}\n```\n\nGenerate operational recipes:\n\n1. SIRC (Synergistic Intent Resonance Cycle):\n   - Intake: capture directive; run Ambiguity Detection; attach IAR\n   - Suggest: generate 3–4 options via Contextual Suggestion Generation; attach metrics; IAR\n   - Lead: present Leading Query; record Keyholder response; IAR\n   - Synthesize: produce Finalize Resonant Objective; threshold ObjectiveClaritY > 0.85; IAR\n   - Plan: RISE insight_plan; gates set; IAR\n   - Execute: handoff to Workflow Engine; per‑step IAR; Vetting Agent checks\n\n2. Metacognitive shifT:\n   - Trigger: IAR confidence < 0.6, validation failure, ethical flag\n   - Pause workflow; snapshot context and last N IARs\n   - CRC analysis; identify dissonance root cause(s)\n   - Propose correction (tool switch, parameter change, new data); IAR\n   - Apply and resume; escalate via Escalation Gates if still low confidence\n\n3. Insight Solidification:\n   - Input: candidate_insight, evidence, source_iars\n   - Vet: run Vetting Agent across logic/ethics/facts/protocol; IAR\n   - Author: draft SPR definition; link blueprint_details and relationships\n   - Persist: SPR Manager writes to knowledge_graph/spr_definitions_tv.json; IAR\n   - Broadcast: emit insight.solidified Protocol Event\n\n4. Phoenix (Autonomous Evolution):\n   - Trigger: repeated low confidence in a capability, or strong improvement candidate from ACO\n   - Propose: ACO controller_update; forecast impact with Predictive/Causal\n   - Decide: Autonomous Orchestrator rollout_decision with safeguards\n   - Adopt: version bump; register evolved capability; emit events; IAR\n\nReturn JSON with recipe implementations, file paths, and integration points.",
        "max_tokens": 1800,
        "temperature": 0.3
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["ingest_canonical_specification", "safety_gate_check"],
              "condition": "{{ safety_gate_check.result.result.safety_gate_passed == true }}"
    },

    "generate_compliance_matrix": {
      "description": "Generate comprehensive compliance matrix mapping v3.5-GP specifications to contracts and implementation requirements.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Generate a comprehensive compliance matrix for ResonantiA Protocol v3.5-GP, mapping specifications to contracts, implementation requirements, and validation criteria. Include orchestrator contracts, tool contracts, Critical Mandates compliance, and Protocol Event Schema requirements.",
        "prompt": "Protocol Text (for compliance context):\n```\n{{ingest_canonical_specification.result.result.spec_text}}\n```\n\nGenerate compliance matrix covering:\n\n1. Orchestrator Contracts:\n   - ACO: pattern evolution, emergent domain detection, controller generation\n   - RISE: deep insight generation, strategic synthesis, hypothesis planning\n   - Autonomous: work management, task prioritization, escalation gates\n\n2. Tool Contracts:\n   - Workflow Engine, Action Registry, Action Context\n   - Prompt Manager, Enhanced LLM Provider, Web Search Tool\n   - Code Executor, Predictive Modeling, Causal Inference\n   - ABM DSL Engine, Agent Based Modeling, Temporal Reasoning\n   - Insight Solidification, Vetting Agent, Token Cache Manager\n   - Websocket Bridge, Visual Cognitive Debugger, Executable Spec Parser\n   - Quantum Utils, Config, SPR Manager\n\n3. Critical Mandates Compliance:\n   - Crucible, Proactive Truth Resonance, Cognitive Tools Actuation\n   - Collective Intelligence, Implementation resonancE, Temporal resonancE\n   - Guardian, Crystal, Visionary, Heartbeat, Phoenix, Utopian\n\n4. Protocol Event Schema:\n   - registry.instance.registered, orchestrator.task.created\n   - insight.solidified, error.detected, shift.triggered\n   - security.override.used\n\n5. IAR Schema Compliance:\n   - Standard IAR structure with confidence, tactical_resonance\n   - crystallization_potential, potential_issues, notes\n\nReturn JSON with compliance matrix, validation criteria, and implementation checklists.",
        "max_tokens": 3600,
        "temperature": 0.25
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["ingest_canonical_specification", "safety_gate_check"],
              "condition": "{{ safety_gate_check.result.result.safety_gate_passed == true }}"
    },

    "generate_genesis_report": {
      "description": "Generate comprehensive genesis report including SPRs, activation map, blueprints, operational recipes, compliance matrix, and v3.5-GP alignment.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Produce a comprehensive engineering report for ResonantiA Protocol v3.5-GP genesis, capturing all decisions, artifacts, compliance status, and next actions. Include orchestrator contracts, Critical Mandates integration, operational recipes, and Protocol Event Schema compliance. Prefer bullet lists and short sections with clear action items.",
        "prompt": "Resonant Autopoietic Genesis Report (v3.5-GP)\n\nAuthor: {{initial_context.author | default('Keyholder')}}\nSpec File: {{ingest_canonical_specification.result.result.path_used}}\nSpec Hash: {{ingest_canonical_specification.result.result.sha256}}\nProtocol Version: 3.5-GP (Genesis Protocol)\nTarget Architecture: Four_PointO_ArchE v4.0\n\nExisting Architecture Analysis:\n```json\n{{analyze_existing_architecture.result.result.architecture_analysis}}\n```\n\nRecognized SPRs (JSON):\n```json\n{{deconstruct_and_recognize_sprs.response_text}}\n```\n\nActivation Map (JSON):\n```json\n{{compute_activation_map.response_text}}\n```\n\nModule Blueprints (excerpt):\n```\n{{generate_module_blueprints.response_text}}\n```\n\nOperational Recipes (excerpt):\n```\n{{generate_operational_recipes.response_text}}\n```\n\nCompliance Matrix (excerpt):\n```\n{{generate_compliance_matrix.response_text}}\n```\n\nPlease compile:\n1. Executive Summary\n2. Four_PointO_ArchE v4.0 Integration Strategy\n3. Activated SPRs and rationale (orchestrators, tools, mandates, concepts)\n4. Module blueprint highlights (including orchestrator contracts)\n5. Critical Mandates integration status\n6. Operational recipes implementation status\n7. Compliance matrix validation status\n8. Protocol Event Schema compliance\n9. IAR Schema compliance\n10. Integration points and enhancement strategy\n11. Detected risks/assumptions\n12. Next steps to complete implementations and tests\n13. v3.5-GP alignment verification",
        "max_tokens": 2000,
        "temperature": 0.25
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["deconstruct_and_recognize_sprs", "analyze_existing_architecture", "compute_activation_map", "generate_module_blueprints", "generate_operational_recipes", "generate_compliance_matrix"]
    },

    "validate_iar_schema": {
      "description": "Validate IAR schema compliance against v3.5-GP standard schema requirements.",
      "action_type": "generate_text_llm",
      "inputs": {
        "system_prompt": "Validate IAR schema compliance for ResonantiA Protocol v3.5-GP. Check that all generated components follow the standard IAR schema with required fields: confidence, tactical_resonance, crystallization_potential, potential_issues, notes. Ensure IAR compliance across all orchestrator contracts, tool contracts, and operational recipes.",
        "prompt": "Generated Components:\n\nModule Blueprints:\n```\n{{generate_module_blueprints.response_text}}\n```\n\nOperational Recipes:\n```\n{{generate_operational_recipes.response_text}}\n```\n\nCompliance Matrix:\n```\n{{generate_compliance_matrix.response_text}}\n```\n\nValidate IAR Schema Compliance:\n\nRequired IAR Schema (v3.5-GP):\n```json\n{\n  \"type\": \"object\",\n  \"required\": [\"confidence\"],\n  \"properties\": {\n    \"confidence\": { \"type\": \"number\", \"minimum\": 0, \"maximum\": 1 },\n    \"tactical_resonance\": { \"type\": \"string\", \"enum\": [\"low\", \"medium\", \"high\"] },\n    \"crystallization_potential\": { \"type\": \"string\", \"enum\": [\"low\", \"medium\", \"high\"] },\n    \"potential_issues\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n    \"notes\": { \"type\": \"string\" }\n  },\n  \"additionalProperties\": true\n}\n```\n\nCheck for:\n1. IAR presence in all tool calls\n2. Confidence bounds (0-1)\n3. Proper tactical_resonance values\n4. Crystallization_potential assessment\n5. Potential_issues annotation\n6. Notes field usage\n7. Additional properties compliance\n\nReturn JSON with validation results, compliance status, and recommendations.",
        "max_tokens": 1200,
        "temperature": 0.2
      },
      "outputs": {
        "response_text": "string",
        "error": "string"
      },
      "dependencies": ["generate_module_blueprints", "generate_operational_recipes", "generate_compliance_matrix"]
    },

    "safety_validation": {
      "description": "Validate safety measures and create rollback capabilities before any code generation.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import os, json, hashlib, datetime\nfrom pathlib import Path\n\n# Safety validation and rollback preparation\ntarget_root = '{{initial_context.target_output_root | default('Four_PointO_ArchE')}}'\n# Ensure target_root doesn't end with slash for proper backup naming\nif target_root.endswith('/'):\n    target_root = target_root[:-1]\nres = {'error': None, 'safety_status': {}, 'rollback_ready': False, 'validation_passed': False}\n\ntry:\n    # Check if backup exists\n    backup_dirs = [d for d in os.listdir('.') if d.startswith(f'{os.path.basename(target_root)}_backup_')]\n    if not backup_dirs:\n        res['error'] = 'No backup found. Cannot proceed without safety backup.'\n        print(json.dumps(res))\n        exit()\n    \n    latest_backup = sorted(backup_dirs)[-1]\n    backup_path = os.path.join('.', latest_backup)\n    \n    # Load safety manifest\n    safety_manifest_path = os.path.join(backup_path, 'safety_manifest.json')\n    if not os.path.exists(safety_manifest_path):\n        res['error'] = 'Safety manifest not found. Cannot verify backup integrity.'\n        print(json.dumps(res))\n        exit()\n    \n    with open(safety_manifest_path, 'r') as f:\n        safety_manifest = json.load(f)\n    \n    # Validate file integrity\n    integrity_checks = []\n    for file_info in safety_manifest.get('critical_files', []):\n        file_path = os.path.join(target_root, file_info['path'])\n        if os.path.exists(file_path):\n            with open(file_path, 'rb') as f:\n                current_hash = hashlib.sha256(f.read()).hexdigest()\n            \n            integrity_checks.append({\n                'file': file_info['path'],\n                'original_hash': file_info['hash'],\n                'current_hash': current_hash,\n                'integrity_ok': current_hash == file_info['hash'],\n                'size_ok': os.path.getsize(file_path) == file_info['size']\n            })\n        else:\n            integrity_checks.append({\n                'file': file_info['path'],\n                'status': 'missing',\n                'integrity_ok': False\n            })\n    \n    # Create rollback script\n    rollback_script = f'''#!/bin/bash\n# Rollback script for Four_PointO_ArchE\n# Generated: {datetime.datetime.now().isoformat()}\n\nset -e\n\necho \"SAFETY ROLLBACK: Restoring Four_PointO_ArchE from backup\"\necho \"Backup location: {backup_path}\"\necho \"Target location: {target_root}\"\n\n# Verify backup exists\nif [ ! -d \"{backup_path}\" ]; then\n    echo \"ERROR: Backup directory not found at {backup_path}\"\n    exit 1\nfi\n\n# Create safety checkpoint before rollback\nif [ -d \"{target_root}\" ]; then\n    echo \"Creating safety checkpoint...\"\n    cp -r \"{target_root}\" \"{target_root}_pre_rollback_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}\"\nfi\n\n# Perform rollback\necho \"Performing rollback...\"\nrm -rf \"{target_root}\"\ncp -r \"{backup_path}\" \"{target_root}\"\n\n# Verify rollback\nif [ -d \"{target_root}\" ]; then\n    echo \"SUCCESS: Rollback completed successfully\"\n    echo \"Original ArchE capabilities restored\"\nelse\n    echo \"ERROR: Rollback failed\"\n    exit 1\nfi\n'''\n    \n    rollback_script_path = os.path.join(target_root, 'rollback.sh')\n    with open(rollback_script_path, 'w') as f:\n        f.write(rollback_script)\n    os.chmod(rollback_script_path, 0o755)\n    \n    # Safety status\n    all_integrity_ok = all(check.get('integrity_ok', False) for check in integrity_checks)\n    \n    res['safety_status'] = {\n        'backup_found': True,\n        'backup_location': backup_path,\n        'safety_manifest_loaded': True,\n        'integrity_checks': integrity_checks,\n        'all_files_intact': all_integrity_ok,\n        'rollback_script_created': rollback_script_path,\n        'rollback_ready': True,\n        'validation_passed': all_integrity_ok\n    }\n    \n    res['rollback_ready'] = True\n    res['validation_passed'] = all_integrity_ok\n    \n    if not all_integrity_ok:\n        res['error'] = 'File integrity validation failed. Some files may have been modified.'\n    \nexcept Exception as e:\n    res['error'] = str(e)\n    res['rollback_ready'] = False\n    res['validation_passed'] = False\n\nprint(json.dumps(res))"
      },
      "outputs": {
        "safety_status": "any",
        "rollback_ready": "boolean",
        "validation_passed": "boolean",
        "error": "string"
      },
      "dependencies": ["analyze_existing_architecture"]
    },

    "create_rollback_capability": {
      "description": "Create comprehensive rollback capability and safety documentation.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import os, json, datetime\n\n# Create comprehensive rollback capability\ntarget_root = '{{initial_context.target_output_root | default('Four_PointO_ArchE')}}'\n# Ensure target_root doesn't end with slash for proper backup naming\nif target_root.endswith('/'):\n    target_root = target_root[:-1]\nres = {'error': None, 'rollback_created': False, 'safety_docs': []}\n\ntry:\n    # Create safety documentation\n    safety_docs = {\n        'rollback_instructions': {\n            'title': 'Four_PointO_ArchE Safety Rollback Instructions',\n            'version': '1.0',\n            'created': datetime.datetime.now().isoformat(),\n            'steps': [\n                '1. Stop any running ArchE processes',\n                '2. Run: ./rollback.sh',\n                '3. Verify original functionality',\n                '4. Check file integrity with: python verify_integrity.py'\n            ],\n            'emergency_contact': 'Keyholder',\n            'backup_locations': []\n        },\n        'safety_checklist': {\n            'pre_modification': [\n                '✓ Backup created',\n                '✓ File integrity verified',\n                '✓ Rollback script generated',\n                '✓ Safety manifest created'\n            ],\n            'post_modification': [\n                '✓ Test original functionality',\n                '✓ Verify new features work',\n                '✓ Check for conflicts',\n                '✓ Update documentation'\n            ]\n        }\n    }\n    \n    # Create safety documentation files\n    safety_doc_path = os.path.join(target_root, 'SAFETY_README.md')\n    with open(safety_doc_path, 'w') as f:\n        f.write(f'''# Four_PointO_ArchE Safety Documentation\n\n## Emergency Rollback\n\nIf any issues occur after v3.5-GP integration:\n\n```bash\n# Quick rollback\\./rollback\\.sh\n\n# Verify restoration\npython verify_integrity\\.py\n```\n\n## Safety Measures Implemented\n\n- **Automatic Backup**: Created before any modifications\n- **File Integrity**: SHA256 hashes for all critical files\n- **Rollback Script**: One-command restoration\n- **Safety Manifest**: Complete change tracking\n- **Verification Tools**: Integrity checking utilities\n\n## Backup Locations\n\n{safety_docs['rollback_instructions']['backup_locations']}\n\n## Contact\n\nEmergency: Keyholder\nCreated: {datetime.datetime.now().isoformat()}\n''')\n    \n    # Create integrity verification script\n    verify_script = '''#!/usr/bin/env python3\n\"\"\"\nIntegrity verification script for Four_PointO_ArchE\n\"\"\"\nimport os, json, hashlib\n\ndef verify_integrity():\n    target_root = os.path.dirname(os.path.abspath(__file__))\n    backup_dirs = [d for d in os.listdir('.') if d.startswith(f'{os.path.basename(target_root)}_backup_')]\n    \n    if not backup_dirs:\n        print(\"ERROR: No backup found\")\n        return False\n    \n    latest_backup = sorted(backup_dirs)[-1]\n    safety_manifest_path = os.path.join(latest_backup, 'safety_manifest.json')\n    \n    if not os.path.exists(safety_manifest_path):\n        print(\"ERROR: Safety manifest not found\")\n        return False\n    \n    with open(safety_manifest_path, 'r') as f:\n        manifest = json.load(f)\n    \n    all_good = True\n    for file_info in manifest.get('critical_files', []):\n        file_path = os.path.join(target_root, file_info['path'])\n        if os.path.exists(file_path):\n            with open(file_path, 'rb') as f:\n                current_hash = hashlib.sha256(f.read()).hexdigest()\n            \n            if current_hash == file_info['hash']:\n                print(f\"✓ {file_info['path']} - OK\")\n            else:\n                print(f\"✗ {file_info['path']} - MODIFIED\")\n                all_good = False\n        else:\n            print(f\"✗ {file_info['path']} - MISSING\")\n            all_good = False\n    \n    return all_good\n\nif __name__ == '__main__':\n    if verify_integrity():\n        print(\"\\nSUCCESS: All files verified\")\n    else:\n        print(\"\\nWARNING: Some files have been modified\")\n'''\n    \n    verify_script_path = os.path.join(target_root, 'verify_integrity.py')\n    with open(verify_script_path, 'w') as f:\n        f.write(verify_script)\n    os.chmod(verify_script_path, 0o755)\n    \n    res['rollback_created'] = True\n    res['safety_docs'] = [\n        'SAFETY_README.md',\n        'rollback.sh',\n        'verify_integrity.py'\n    ]\n    \nexcept Exception as e:\n    res['error'] = str(e)\n    res['rollback_created'] = False\n\nprint(json.dumps(res))"
      },
      "outputs": {
        "rollback_created": "boolean",
        "safety_docs": "list",
        "error": "string"
      },
      "dependencies": ["safety_validation"]
    },

    "safety_gate_check": {
      "description": "Final safety gate check before allowing any code generation tasks to proceed.",
      "action_type": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import os, json\n\n# Final safety gate check\ntarget_root = '{{initial_context.target_output_root | default('Four_PointO_ArchE')}}'\n# Ensure target_root doesn't end with slash for proper backup naming\nif target_root.endswith('/'):\n    target_root = target_root[:-1]\nres = {'error': None, 'safety_gate_passed': False, 'safety_summary': {}}\n\ntry:\n    # Check all safety requirements\n    safety_checks = {\n        'backup_exists': False,\n        'backup_has_manifest': False,\n        'rollback_script_created': False,\n        'verification_script_created': False,\n        'safety_docs_created': False,\n        'file_integrity_ok': False\n    }\n    \n    # Check backup exists\n    backup_dirs = [d for d in os.listdir('.') if d.startswith(f'{os.path.basename(target_root)}_backup_')]\n    if backup_dirs:\n        safety_checks['backup_exists'] = True\n        latest_backup = sorted(backup_dirs)[-1]\n        \n        # Check safety manifest\n        safety_manifest_path = os.path.join(latest_backup, 'safety_manifest.json')\n        if os.path.exists(safety_manifest_path):\n            safety_checks['backup_has_manifest'] = True\n    \n    # Check rollback script\n    rollback_script_path = os.path.join(target_root, 'rollback.sh')\n    if os.path.exists(rollback_script_path):\n        safety_checks['rollback_script_created'] = True\n    \n    # Check verification script\n    verify_script_path = os.path.join(target_root, 'verify_integrity.py')\n    if os.path.exists(verify_script_path):\n        safety_checks['verification_script_created'] = True\n    \n    # Check safety docs\n    safety_doc_path = os.path.join(target_root, 'SAFETY_README.md')\n    if os.path.exists(safety_doc_path):\n        safety_checks['safety_docs_created'] = True\n    \n    # Check file integrity (assume true if we got this far and backup exists)\n    if safety_checks['backup_exists'] and safety_checks['backup_has_manifest']:\n        safety_checks['file_integrity_ok'] = True\n    \n    # All safety checks must pass\n    all_checks_passed = all(safety_checks.values())\n    \n    res['safety_gate_passed'] = all_checks_passed\n    res['safety_summary'] = {\n        'checks': safety_checks,\n        'all_passed': all_checks_passed,\n        'backup_location': latest_backup if backup_dirs else None,\n        'rollback_available': safety_checks['rollback_script_created'],\n        'verification_available': safety_checks['verification_script_created']\n    }\n    \n    if not all_checks_passed:\n        failed_checks = [k for k, v in safety_checks.items() if not v]\n        res['error'] = f'Safety gate failed. Missing: {failed_checks}'\n    \nexcept Exception as e:\n    res['error'] = str(e)\n    res['safety_gate_passed'] = False\n\nprint(json.dumps(res))"
      },
      "outputs": {
        "safety_gate_passed": "boolean",
        "safety_summary": "any",
        "error": "string"
      },
      "dependencies": ["create_rollback_capability"]
    },

    "display_report": {
      "description": "Display the final comprehensive genesis report with v3.5-GP alignment and safety information.",
      "action_type": "display_output",
      "inputs": {
        "content": "# Resonant Autopoietic Genesis Report (v3.5-GP)\n\n{{generate_genesis_report.result.result.generated_text | default('Report generation failed.')}}\n\n## IAR Schema Validation\n\n{{validate_iar_schema.result.result.generated_text | default('IAR validation failed.')}}\n\n## Safety Status\n\n**Backup Created**: {{analyze_existing_architecture.result.result.backup_created | default('Unknown')}}\n**Backup Location**: {{analyze_existing_architecture.result.result.backup_location | default('Not available')}}\n**Rollback Ready**: {{safety_validation.result.result.rollback_ready | default('Unknown')}}\n**Validation Passed**: {{safety_validation.result.result.validation_passed | default('Unknown')}}\n\n### Safety Measures Implemented\n\n- ✅ **Automatic Backup**: Complete system backup created before any modifications\n- ✅ **File Integrity**: SHA256 hashes for all critical files\n- ✅ **Rollback Script**: One-command restoration (./rollback.sh)\n- ✅ **Safety Manifest**: Complete change tracking\n- ✅ **Verification Tools**: Integrity checking utilities (python verify_integrity.py)\n- ✅ **Safety Documentation**: Comprehensive safety guide (SAFETY_README.md)\n\n### Emergency Rollback Instructions\n\nIf any issues occur after v3.5-GP integration:\n\n```bash\n# Quick rollback\n./rollback.sh\n\n# Verify restoration\npython verify_integrity.py\n```\n\n### Safety Checklist\n\n**Pre-Modification**:\n- ✅ Backup created\n- ✅ File integrity verified\n- ✅ Rollback script generated\n- ✅ Safety manifest created\n\n**Post-Modification**:\n- ⏳ Test original functionality\n- ⏳ Verify new features work\n- ⏳ Check for conflicts\n- ⏳ Update documentation\n\n**Safety Documentation Created**:\n{{create_rollback_capability.result.result.safety_docs | default('None')}}"
      },
      "outputs": {
        "status": "string"
      },
      "dependencies": ["generate_genesis_report", "validate_iar_schema", "analyze_existing_architecture", "safety_validation", "create_rollback_capability"]
    }
  },
  "start_tasks": ["ingest_canonical_specification"]
}
