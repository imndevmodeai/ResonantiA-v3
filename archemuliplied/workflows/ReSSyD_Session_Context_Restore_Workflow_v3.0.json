{
  "name": "ReSSyD Session Context Restore Workflow (v3.0)",
  "description": "Loads and presents a previously captured session context capsule.",
  "version": "3.0",
  "tasks": {
    "load_capsule_file": {
      "description": "Load the session context capsule from the specified file.",
      "action": "execute_code",
      "inputs": {
        "language": "python",
        "code": "import json\nimport os\n\n# Get capsule filepath from context\ncapsule_filepath = context.get('initial_context', {}).get('capsule_filepath')\nif not capsule_filepath:\n    raise ValueError('No capsule_filepath provided in initial_context')\n\nif not os.path.exists(capsule_filepath):\n    raise FileNotFoundError(f'Session Context Capsule file not found at: {capsule_filepath}')\n\n# Load the complete session capsule without any truncation\ntry:\n    with open(capsule_filepath, 'r', encoding='utf-8') as f:\n        session_capsule_data = json.load(f)\n    \n    # Verify the loaded data is complete\n    if not isinstance(session_capsule_data, dict):\n        raise ValueError('Loaded capsule data is not a dictionary')\n    \n    # Log the size and structure to ensure complete loading\n    capsule_size = os.path.getsize(capsule_filepath)\n    print(f'Successfully loaded session context capsule from: {capsule_filepath}')\n    print(f'Capsule file size: {capsule_size} bytes')\n    print(f'Capsule contains keys: {list(session_capsule_data.keys())}')\n    \n    # Ensure no data truncation occurred\n    if 'keyholder_notes' in session_capsule_data:\n        notes_length = len(str(session_capsule_data['keyholder_notes']))\n        print(f'Keyholder notes length: {notes_length} characters')\n    \n    if 'arche_context_snapshot' in session_capsule_data:\n        context_str = json.dumps(session_capsule_data['arche_context_snapshot'], default=str)\n        print(f'Arche context snapshot size: {len(context_str)} characters')\n    \n    result = {'session_capsule_data': session_capsule_data, 'capsule_filepath': capsule_filepath}\n    \nexcept json.JSONDecodeError as e:\n    raise ValueError(f'Invalid JSON in capsule file: {e}')\nexcept Exception as e:\n    raise RuntimeError(f'Error loading capsule: {e}')"
      },
      "outputs": {"session_capsule_data": "dict", "capsule_filepath": "string", "reflection": "dict"},
      "dependencies": []
    },
    "display_loaded_context": {
      "description": "Display the loaded session context for review.",
      "action": "display_output",
      "inputs": {
        "content": "{{ load_capsule_file.session_capsule_data }}",
        "format": "json"
      },
      "dependencies": ["load_capsule_file"],
      "condition": "{{ load_capsule_file.reflection.status == 'Success' }}"
    },
    "prime_arche_with_context": {
      "description": "Use LLM to summarize the capsule and prime current session (Conceptual).",
      "action": "invoke_llm",
      "inputs": {
        "prompt": "The following is a 'Session Context Capsule' from a previous ResonantiA development session. Please summarize the key Keyholder notes, Arche's operational context (especially recent IAR highlights or active SPRs if mentioned), and suggest 1-2 immediate focus points for re-engaging with that development state.\n\nIMPORTANT: Analyze the COMPLETE context provided - do not truncate or summarize the input data itself, but provide a comprehensive analysis of all content.\n\nSession Context Capsule:\n```json\n{{ load_capsule_file.session_capsule_data }}\n```\n\nProvide a detailed summary and priming points based on the complete context above:",
        "max_tokens": 1000
      },
      "outputs": {"response_text": "string", "reflection": "dict"},
      "dependencies": ["load_capsule_file"],
      "condition": "{{ load_capsule_file.reflection.status == 'Success' }}"
    },
    "display_priming_summary": {
        "description": "Display the LLM-generated priming summary.",
        "action": "display_output",
        "inputs": {
            "content": {
                "message": "Session context restored. LLM priming summary:",
                "summary": "{{ prime_arche_with_context.response_text }}",
                "original_capsule_file": "{{ load_capsule_file.capsule_filepath }}"
            },
            "format": "json"
        },
        "dependencies": ["prime_arche_with_context"],
        "condition": "{{ prime_arche_with_context.reflection.status == 'Success' }}"
    }
  }
} 