{
  "workflow_id": "platform_extraction_master",
  "description": "Comprehensive multi-platform data extraction workflow for Southwest Michigan region - FetLife, SkipTheGames, Chaturbate with porn star identification and data validation",
  "version": "1.0",
  "input_schema": {
    "type": "object",
    "properties": {
      "target_region": {
        "type": "string",
        "description": "Target region for extraction (default: Southwest Michigan)",
        "default": "Southwest Michigan"
      },
      "extraction_mode": {
        "type": "string",
        "enum": ["full", "incremental", "test"],
        "description": "Extraction mode: full (all profiles), incremental (new only), test (limited sample)",
        "default": "full"
      }
    }
  },
  "tasks": {
    "fetlife_extraction": {
      "action_type": "generate_text_llm",
      "description": "Extract profiles from FetLife for Southwest Michigan region",
      "inputs": {
        "prompt_name": "fetlife_search_extraction",
        "prompt": "You are ArchE executing a FetLife profile search and extraction operation for Southwest Michigan region.\n\n**MISSION OBJECTIVE:**\nExtract comprehensive profile data from FetLife matching: female profiles, couples profiles, located in Southwest Michigan (zip codes: 49001-49999, cities: Kalamazoo, Battle Creek, Portage, etc.).\n\n**EXECUTION PROTOCOL:**\n\n1. **Search Strategy:**\n   - Use FetLife search interface with location filters: Southwest Michigan region\n   - Apply filters: Gender (Female, Couples), Age range (18+), Active status (Last 30 days)\n   - Iterate through search results with pagination handling\n   - Implement rate limiting: 2-3 requests per second to avoid detection\n\n2. **Data Extraction Targets:**\n   - Profile username/handle\n   - Age\n   - Location (city, state, zip if available)\n   - Profile description/bio text\n   - Interests/kinks listed\n   - Profile creation date\n   - Last active timestamp\n   - Profile photo URLs (public only)\n   - Groups/communities joined\n   - Verification status\n   - Any public contact information\n\n3. **Technical Implementation:**\n   - Use Selenium/Playwright for dynamic content rendering\n   - Parse HTML structure: identify profile containers, extract data via CSS selectors\n   - Handle JavaScript-rendered content with appropriate wait times\n   - Implement retry logic for failed requests (max 3 retries with exponential backoff)\n   - Store raw HTML snapshots for validation\n   - Extract structured JSON data per profile\n\n4. **Data Structure Output:**\n   Return JSON array with format:\n   {\n     \"profiles\": [\n       {\n         \"platform\": \"FetLife\",\n         \"username\": \"string\",\n         \"age\": \"integer\",\n         \"location\": {\"city\": \"string\", \"state\": \"string\", \"zip\": \"string\"},\n         \"bio\": \"string\",\n         \"interests\": [\"array\", \"of\", \"strings\"],\n         \"profile_created\": \"ISO8601_date\",\n         \"last_active\": \"ISO8601_date\",\n         \"photo_urls\": [\"array\", \"of\", \"urls\"],\n         \"groups\": [\"array\"],\n         \"verified\": \"boolean\",\n         \"extraction_timestamp\": \"ISO8601_date\",\n         \"profile_url\": \"string\"\n       }\n     ],\n     \"metadata\": {\n       \"total_profiles_found\": \"integer\",\n       \"extraction_date\": \"ISO8601_date\",\n       \"search_parameters\": {\"location\": \"Southwest Michigan\", \"filters\": \"object\"}\n     }\n   }\n\n5. **Error Handling:**\n   - Log all errors with context (URL, timestamp, error type)\n   - Continue extraction on individual profile failures\n   - Return partial results if full extraction fails\n   - Flag profiles with incomplete data for re-extraction\n\n**EXECUTE:** Begin search and extraction process. Return complete JSON output with all extracted profiles.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.2,
        "max_tokens": 16000
      },
      "outputs": {
        "fetlife_data": "{{task_result.result}}"
      }
    },
    "skipthegames_extraction": {
      "action_type": "generate_text_llm",
      "description": "Extract listings from SkipTheGames for Southwest Michigan region",
      "inputs": {
        "prompt_name": "skipthegames_search_extraction",
        "prompt": "You are ArchE executing a SkipTheGames profile search and extraction operation for Southwest Michigan region.\n\n**MISSION OBJECTIVE:**\nExtract comprehensive profile data from SkipTheGames matching: Southwest Michigan location (cities: Kalamazoo, Battle Creek, Portage, Benton Harbor, St. Joseph, etc.).\n\n**EXECUTION PROTOCOL:**\n\n1. **Search Strategy:**\n   - Navigate to SkipTheGames Southwest Michigan section\n   - Parse location-based listings (city pages)\n   - Extract all active listings with location verification\n   - Handle pagination: iterate through all result pages\n   - Implement request throttling: 2 requests/second\n\n2. **Data Extraction Targets:**\n   - Listing title/headline\n   - Provider name/username\n   - Age (if stated)\n   - Location (city, area, neighborhood if specified)\n   - Phone number (if public)\n   - Email (if public)\n   - Service description/ad text\n   - Rates/pricing information\n   - Available services listed\n   - Photos/images (URLs)\n   - Posting date\n   - Last updated timestamp\n   - Verification badges/status\n   - Social media links (if provided)\n   - Website links (if provided)\n\n3. **Technical Implementation:**\n   - Use requests library with proper headers (User-Agent rotation)\n   - Parse HTML: identify listing containers, extract via XPath/CSS selectors\n   - Handle dynamic content: wait for JavaScript rendering if needed\n   - Extract phone numbers via regex patterns\n   - Extract email addresses via regex patterns\n   - Download and hash images for duplicate detection\n   - Implement session management for multi-page navigation\n   - Store raw HTML for validation and re-parsing if needed\n\n4. **Data Structure Output:**\n   Return JSON array with format:\n   {\n     \"listings\": [\n       {\n         \"platform\": \"SkipTheGames\",\n         \"listing_id\": \"string\",\n         \"title\": \"string\",\n         \"provider_name\": \"string\",\n         \"age\": \"integer_or_null\",\n         \"location\": {\"city\": \"string\", \"area\": \"string\", \"neighborhood\": \"string\"},\n         \"phone\": \"string_or_null\",\n         \"email\": \"string_or_null\",\n         \"description\": \"string\",\n         \"rates\": \"string\",\n         \"services\": [\"array\"],\n         \"photo_urls\": [\"array\"],\n         \"posting_date\": \"ISO8601_date\",\n         \"last_updated\": \"ISO8601_date\",\n         \"verified\": \"boolean\",\n         \"social_links\": [\"array\"],\n         \"website_links\": [\"array\"],\n         \"listing_url\": \"string\",\n         \"extraction_timestamp\": \"ISO8601_date\"\n       }\n     ],\n     \"metadata\": {\n       \"total_listings_found\": \"integer\",\n       \"extraction_date\": \"ISO8601_date\",\n       \"cities_covered\": [\"array\"],\n       \"search_parameters\": {\"location\": \"Southwest Michigan\"}\n     }\n   }\n\n5. **Error Handling:**\n   - Continue on individual listing failures\n   - Retry failed requests up to 3 times\n   - Log all extraction errors with full context\n   - Return partial results with error summary\n\n**EXECUTE:** Begin search and extraction. Return complete JSON with all extracted listings.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.2,
        "max_tokens": 16000
      },
      "outputs": {
        "skipthegames_data": "{{task_result.result}}"
      }
    },
    "chaturbate_extraction": {
      "action_type": "generate_text_llm",
      "description": "Extract profiles from Chaturbate focusing on modeling/video services in Southwest Michigan",
      "inputs": {
        "prompt_name": "chaturbate_search_extraction",
        "prompt": "You are ArchE executing a Chaturbate profile search and extraction operation focusing on Southwest Michigan region and modeling/video creation services.\n\n**MISSION OBJECTIVE:**\nExtract profile data from Chaturbate for performers advertising modeling or video creation options, with location focus on Southwest Michigan.\n\n**EXECUTION PROTOCOL:**\n\n1. **Search Strategy:**\n   - Access Chaturbate performer directory\n   - Filter by: Online status, Tags (modeling, video, custom content)\n   - Search profile descriptions for location keywords: Michigan, Kalamazoo, Battle Creek, Southwest MI\n   - Extract profile data from performer pages\n   - Implement rate limiting: 1-2 requests per second\n   - Handle authentication if required for deeper access\n\n2. **Data Extraction Targets:**\n   - Performer username\n   - Age (if stated)\n   - Location (if stated in profile)\n   - Profile description/bio\n   - Tags/categories\n   - Services offered (modeling, video creation, custom content)\n   - Social media links (Twitter, Instagram, OnlyFans, etc.)\n   - Website links\n   - Profile photo URLs\n   - Online status\n   - Followers count (if public)\n   - Profile creation date\n   - Last broadcast date\n   - Tip menu/services (if public)\n\n3. **Technical Implementation:**\n   - Use Selenium for dynamic content (Chaturbate uses heavy JavaScript)\n   - Wait for profile content to load (explicit waits for elements)\n   - Parse profile HTML structure\n   - Extract social links via regex and link parsing\n   - Handle popups/modals that may block content\n   - Implement cookie/session management\n   - Store profile screenshots for validation\n   - Extract structured data to JSON\n\n4. **Data Structure Output:**\n   Return JSON array with format:\n   {\n     \"profiles\": [\n       {\n         \"platform\": \"Chaturbate\",\n         \"username\": \"string\",\n         \"age\": \"integer_or_null\",\n         \"location_mentioned\": \"string_or_null\",\n         \"bio\": \"string\",\n         \"tags\": [\"array\"],\n         \"services\": [\"modeling\", \"video_creation\", \"custom_content\"],\n         \"social_links\": {\"twitter\": \"url_or_null\", \"instagram\": \"url_or_null\", \"onlyfans\": \"url_or_null\"},\n         \"website_links\": [\"array\"],\n         \"photo_urls\": [\"array\"],\n         \"online_status\": \"boolean\",\n         \"followers\": \"integer_or_null\",\n         \"profile_created\": \"ISO8601_date_or_null\",\n         \"last_broadcast\": \"ISO8601_date_or_null\",\n         \"tip_menu\": \"string_or_null\",\n         \"profile_url\": \"string\",\n         \"extraction_timestamp\": \"ISO8601_date\"\n       }\n     ],\n     \"metadata\": {\n       \"total_profiles_found\": \"integer\",\n       \"extraction_date\": \"ISO8601_date\",\n       \"search_filters\": {\"location_focus\": \"Southwest Michigan\", \"services\": [\"modeling\", \"video_creation\"]}\n     }\n   }\n\n5. **Error Handling:**\n   - Handle authentication failures gracefully\n   - Continue extraction on individual profile errors\n   - Log all failures with full context\n   - Return partial results with error summary\n   - Flag profiles requiring manual review\n\n**EXECUTE:** Begin search and extraction. Return complete JSON output.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.2,
        "max_tokens": 16000
      },
      "outputs": {
        "chaturbate_data": "{{task_result.result}}"
      }
    },
    "aggregate_data": {
      "action_type": "execute_code",
      "description": "Aggregate all platform extraction results into unified dataset",
      "dependencies": ["fetlife_extraction", "skipthegames_extraction", "chaturbate_extraction"],
      "inputs": {
        "code": "import json\nfrom datetime import datetime\n\n# Get data from previous tasks\nfetlife_data = json.loads('{{fetlife_extraction.fetlife_data}}')\nskipthegames_data = json.loads('{{skipthegames_extraction.skipthegames_data}}')\nchaturbate_data = json.loads('{{chaturbate_extraction.chaturbate_data}}')\n\n# Aggregate all profiles\naggregated_profiles = []\n\n# Add FetLife profiles\nif 'profiles' in fetlife_data:\n    aggregated_profiles.extend(fetlife_data['profiles'])\n\n# Add SkipTheGames listings (convert to profile format)\nif 'listings' in skipthegames_data:\n    for listing in skipthegames_data['listings']:\n        profile = {\n            'platform': 'SkipTheGames',\n            'username': listing.get('provider_name', listing.get('listing_id', '')),\n            'age': listing.get('age'),\n            'location': listing.get('location', {}),\n            'bio': listing.get('description', ''),\n            'phone': listing.get('phone'),\n            'email': listing.get('email'),\n            'services': listing.get('services', []),\n            'photo_urls': listing.get('photo_urls', []),\n            'social_links': listing.get('social_links', []),\n            'website_links': listing.get('website_links', []),\n            'profile_url': listing.get('listing_url', ''),\n            'extraction_timestamp': listing.get('extraction_timestamp', datetime.now().isoformat())\n        }\n        aggregated_profiles.append(profile)\n\n# Add Chaturbate profiles\nif 'profiles' in chaturbate_data:\n    aggregated_profiles.extend(chaturbate_data['profiles'])\n\n# Create aggregated dataset\naggregated_dataset = {\n    'total_profiles': len(aggregated_profiles),\n    'profiles': aggregated_profiles,\n    'platform_breakdown': {\n        'fetlife': len([p for p in aggregated_profiles if p.get('platform') == 'FetLife']),\n        'skipthegames': len([p for p in aggregated_profiles if p.get('platform') == 'SkipTheGames']),\n        'chaturbate': len([p for p in aggregated_profiles if p.get('platform') == 'Chaturbate'])\n    },\n    'aggregation_timestamp': datetime.now().isoformat()\n}\n\nresult = json.dumps(aggregated_dataset, indent=2)\n",
        "language": "python"
      },
      "outputs": {
        "aggregated_data": "{{task_result.result}}"
      }
    },
    "porn_star_identification": {
      "action_type": "generate_text_llm",
      "description": "Identify porn stars/former porn stars in extracted profiles",
      "dependencies": ["aggregate_data"],
      "inputs": {
        "prompt_name": "porn_star_identification",
        "prompt": "You are ArchE executing a porn star/former porn star identification process for profiles advertising modeling or video creation services.\n\n**MISSION OBJECTIVE:**\nIdentify profiles that are current or former porn industry performers advertising modeling/video services in Southwest Michigan region.\n\n**INPUT DATA:**\n{{aggregate_data.aggregated_data}}\n\n**EXECUTION PROTOCOL:**\n\n1. **Identification Strategy:**\n   - Cross-reference extracted profiles against known porn industry databases\n   - Analyze profile images using facial recognition/image matching\n   - Parse profile text for industry keywords, studio names, performer names\n   - Check social media links for industry connections\n   - Search for stage names/aliases in industry databases\n   - Analyze photo metadata for studio watermarks\n\n2. **Data Sources for Cross-Reference:**\n   - IAFD (Internet Adult Film Database)\n   - AdultFilmDatabase\n   - FreeOnes\n   - Pornhub performer pages\n   - Industry news sites\n   - Social media industry connections\n\n3. **Image Analysis:**\n   - Extract profile photos from all platforms\n   - Run facial recognition against industry databases\n   - Detect studio watermarks/logos in images\n   - Analyze image metadata (EXIF data)\n   - Compare against known performer image sets\n   - Calculate similarity scores\n\n4. **Text Analysis:**\n   - Extract all text from profiles (bios, descriptions, tags)\n   - Search for industry keywords: studio names, production companies, industry terms\n   - Identify stage names/aliases\n   - Parse for performer name mentions\n   - Analyze language patterns typical of industry professionals\n\n5. **Confidence Scoring:**\n   - High confidence (90%+): Direct name match, verified industry links, studio watermarks\n   - Medium confidence (70-89%): Strong indicators but not definitive\n   - Low confidence (50-69%): Some indicators present\n   - No match (<50%): Insufficient evidence\n\n6. **Data Structure Output:**\n   Return JSON with format:\n   {\n     \"identified_profiles\": [\n       {\n         \"source_platform\": \"string\",\n         \"source_username\": \"string\",\n         \"identified_as\": {\n           \"stage_name\": \"string_or_null\",\n           \"real_name\": \"string_or_null\",\n           \"aliases\": [\"array\"],\n           \"industry_status\": \"current\" | \"former\" | \"unknown\",\n           \"studios\": [\"array\"],\n           \"confidence_score\": \"float_0_to_1\",\n           \"match_type\": \"name_match\" | \"image_match\" | \"text_match\" | \"combined\",\n           \"evidence\": [\"array_of_evidence_strings\"],\n           \"industry_links\": [\"array_of_urls\"],\n           \"verification_date\": \"ISO8601_date\"\n         },\n         \"modeling_video_services\": \"boolean\",\n         \"location\": \"string\",\n         \"profile_url\": \"string\"\n       }\n     ],\n     \"metadata\": {\n       \"total_profiles_analyzed\": \"integer\",\n       \"total_identified\": \"integer\",\n       \"high_confidence_matches\": \"integer\",\n       \"medium_confidence_matches\": \"integer\",\n       \"low_confidence_matches\": \"integer\",\n       \"analysis_date\": \"ISO8601_date\"\n     }\n   }\n\n7. **Technical Implementation:**\n   - Use facial recognition libraries (face_recognition, DeepFace)\n   - Implement image hashing for duplicate detection\n   - Web scrape industry databases (with rate limiting)\n   - Use NLP for text analysis and keyword extraction\n   - Store all evidence for manual review\n   - Implement confidence threshold filtering\n\n**EXECUTE:** Begin identification process. Return complete JSON with all identified profiles and confidence scores.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.1,
        "max_tokens": 16000
      },
      "outputs": {
        "identification_results": "{{task_result.result}}"
      }
    },
    "data_validation_cleaning": {
      "action_type": "generate_text_llm",
      "description": "Validate, clean, and deduplicate all extracted profile data",
      "dependencies": ["aggregate_data", "porn_star_identification"],
      "inputs": {
        "prompt_name": "data_validation_cleaning",
        "prompt": "You are ArchE executing data validation and cleaning operations on extracted platform profile data.\n\n**INPUT DATA:**\nAggregated Profiles: {{aggregate_data.aggregated_data}}\nIdentification Results: {{porn_star_identification.identification_results}}\n\n**MISSION OBJECTIVE:**\nValidate, clean, normalize, and deduplicate all extracted profile data to ensure accuracy and completeness.\n\n**EXECUTION PROTOCOL:**\n\n1. **Validation Rules:**\n   - Verify all required fields are present\n   - Validate data types (age is integer, dates are ISO8601, etc.)\n   - Check data ranges (age 18-99, valid zip codes, etc.)\n   - Validate URLs are properly formatted\n   - Verify phone numbers match standard formats\n   - Validate email addresses\n   - Check location data consistency\n\n2. **Cleaning Operations:**\n   - Remove HTML tags and entities from text fields\n   - Normalize whitespace (trim, collapse multiple spaces)\n   - Standardize date formats to ISO8601\n   - Normalize phone numbers to E.164 format\n   - Clean and validate email addresses\n   - Standardize location formats (city, state, zip)\n   - Remove duplicate entries (same username across platforms)\n   - Merge duplicate profiles (same person, different platforms)\n   - Remove invalid or malformed data\n   - Flag incomplete profiles for review\n\n3. **Deduplication Strategy:**\n   - Compare usernames across platforms\n   - Match phone numbers across platforms\n   - Match email addresses across platforms\n   - Use fuzzy matching for similar names\n   - Compare profile photos (image hashing)\n   - Merge duplicate entries into single profile records\n   - Preserve all source platform references\n\n4. **Data Completeness Scoring:**\n   - Calculate completeness percentage per profile\n   - Required fields: username, platform, extraction_date\n   - High value fields: age, location, contact info, bio\n   - Score: (fields_present / total_fields) * 100\n   - Flag profiles below 50% completeness\n\n5. **Data Structure Output:**\n   Return JSON with format:\n   {\n     \"cleaned_profiles\": [\n       {\n         \"profile_id\": \"unique_string\",\n         \"platforms\": [\"array_of_platforms\"],\n         \"username\": \"string\",\n         \"normalized_data\": {\n           \"age\": \"integer_or_null\",\n           \"location\": {\"city\": \"string\", \"state\": \"string\", \"zip\": \"string\"},\n           \"phone\": \"E164_format_or_null\",\n           \"email\": \"string_or_null\",\n           \"bio\": \"cleaned_string\",\n           \"interests\": [\"normalized_array\"],\n           \"services\": [\"normalized_array\"],\n           \"social_links\": {\"normalized_object\"},\n           \"photo_urls\": [\"validated_array\"],\n           \"extraction_dates\": [\"ISO8601_array\"]\n         },\n         \"completeness_score\": \"float_0_to_100\",\n         \"validation_status\": \"complete\" | \"incomplete\" | \"flagged\",\n         \"validation_errors\": [\"array_or_empty\"],\n         \"duplicate_of\": \"profile_id_or_null\",\n         \"merged_from\": [\"array_of_profile_ids\"],\n         \"porn_star_identification\": \"object_or_null\"\n       }\n     ],\n     \"metadata\": {\n       \"total_profiles_input\": \"integer\",\n       \"total_profiles_output\": \"integer\",\n       \"duplicates_removed\": \"integer\",\n       \"profiles_merged\": \"integer\",\n       \"validation_errors_count\": \"integer\",\n       \"completeness_stats\": {\n         \"average_completeness\": \"float\",\n         \"complete_profiles\": \"integer\",\n         \"incomplete_profiles\": \"integer\",\n         \"flagged_profiles\": \"integer\"\n       },\n       \"processing_date\": \"ISO8601_date\"\n     }\n   }\n\n6. **Technical Implementation:**\n   - Use pandas for data manipulation\n   - Implement data validation schemas (JSON Schema, Pydantic)\n   - Use fuzzywuzzy for name matching\n   - Implement image hashing (perceptual hashing)\n   - Use regex for phone/email validation\n   - Store validation logs for audit trail\n   - Export cleaned data to CSV/JSON for analysis\n\n**EXECUTE:** Begin validation and cleaning. Return complete JSON with cleaned, validated, deduplicated data.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.1,
        "max_tokens": 16000
      },
      "outputs": {
        "cleaned_data": "{{task_result.result}}"
      }
    },
    "generate_final_report": {
      "action_type": "generate_text_llm",
      "description": "Generate comprehensive final execution report",
      "dependencies": ["fetlife_extraction", "skipthegames_extraction", "chaturbate_extraction", "porn_star_identification", "data_validation_cleaning"],
      "inputs": {
        "prompt_name": "final_report_generation",
        "prompt": "You are ArchE generating a comprehensive final report for the platform extraction workflow.\n\n**INPUT DATA:**\nFetLife Results: {{fetlife_extraction.fetlife_data}}\nSkipTheGames Results: {{skipthegames_extraction.skipthegames_data}}\nChaturbate Results: {{chaturbate_extraction.chaturbate_data}}\nIdentification Results: {{porn_star_identification.identification_results}}\nCleaned Data: {{data_validation_cleaning.cleaned_data}}\n\n**MISSION OBJECTIVE:**\nGenerate a comprehensive, structured report summarizing all extraction activities, results, statistics, and recommendations.\n\n**REPORT STRUCTURE:**\n\n1. **Executive Summary**\n   - Total profiles extracted across all platforms\n   - Porn stars identified (with confidence breakdown)\n   - Data quality metrics\n   - Key findings\n\n2. **Platform Breakdown**\n   - FetLife: profiles extracted, success rate, errors\n   - SkipTheGames: listings extracted, success rate, errors\n   - Chaturbate: profiles extracted, success rate, errors\n\n3. **Identification Analysis**\n   - Total profiles analyzed\n   - Porn stars identified (high/medium/low confidence)\n   - Identification methods used\n   - Evidence quality assessment\n\n4. **Data Quality Metrics**\n   - Completeness scores\n   - Validation errors\n   - Duplicates removed\n   - Profiles merged\n\n5. **Recommendations**\n   - Areas for improvement\n   - Data gaps identified\n   - Suggested next steps\n\n**OUTPUT FORMAT:**\nReturn a comprehensive JSON report with all statistics, summaries, and recommendations.",
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "temperature": 0.3,
        "max_tokens": 8000
      },
      "outputs": {
        "final_report": "{{task_result.result}}"
      }
    }
  }
}

