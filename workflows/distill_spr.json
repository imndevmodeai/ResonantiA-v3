{
    "workflow_name": "Distill SPR from Execution",
    "version": "1.0",
    "description": "Analyzes a completed thought trail and final strategy to distill a new Sparse Priming Representation (SPR). This forms the learning and memory mechanism of the RISE engine.",
    "input_parameters": {
        "thought_trail": {
            "type": "list",
            "description": "The complete thought trail from the RISE execution session."
        },
        "final_strategy": {
            "type": "dict",
            "description": "The final, vetted strategy that was successfully produced."
        },
        "session_id": {
            "type": "string",
            "description": "The unique ID of the session being analyzed."
        },
        "problem_description": {
            "type": "string",
            "description": "The original problem description."
        }
    },
    "tasks": {
        "format_distillation_prompt": {
            "action_type": "string_template",
            "description": "Formats the inputs into a comprehensive prompt for the LLM.",
            "inputs": {
                "template": "Analyze the following problem-solving session to generate a new Sparse Priming Representation (SPR). The SPR should capture the core successful pattern demonstrated in this execution. Be concise, abstract, and focus on the reusable strategic logic.\\n\\n== PROBLEM ==\\n{problem_description}\\n\\n== FINAL STRATEGY ==\\n{final_strategy_str}\\n\\n== THOUGHT TRAIL ==\\n{thought_trail_str}\\n\\nBased on the above, generate a JSON object for the new SPR with the following keys: 'spr_id', 'term', 'description', 'category', 'pattern_type', 'core_logic', 'aliases', and 'confidence_score'. The spr_id should be a descriptive CamelCase name. The description should be a single sentence. The core_logic should be a bulleted list of the key steps. Confidence score should be a float between 0.0 and 1.0.",
                "problem_description": "{{ inputs.problem_description }}",
                "final_strategy_str": "{{ inputs.final_strategy }}",
                "thought_trail_str": "{{ inputs.thought_trail }}"
            },
            "output_variable": "distillation_prompt"
        },
        "distill_spr_with_llm": {
            "action_type": "generate_text_llm",
            "description": "Uses a powerful language model to analyze the session and generate the SPR JSON.",
            "inputs": {
                "prompt": "{{ tasks.format_distillation_prompt.output.result }}",
                "model_settings": {
                    "temperature": 0.3,
                    "max_tokens": 1000
                }
            },
            "output_variable": "llm_spr_output",
            "dependencies": ["format_distillation_prompt"]
        },
        "parse_and_validate_spr": {
            "action_type": "execute_code",
            "description": "Parses the LLM output and validates the structure of the generated SPR.",
            "inputs": {
                "code": "import json\ndef parse_spr(llm_output):\n    try:\n        spr_data = json.loads(llm_output)\n        required_keys = ['spr_id', 'term', 'description', 'category', 'pattern_type', 'core_logic', 'aliases', 'confidence_score']\n        for key in required_keys:\n            if key not in spr_data:\n                return {'status': 'error', 'message': f'Missing key in SPR: {key}'}\n        return {'status': 'success', 'spr_definition': spr_data}\n    except Exception as e:\n        return {'status': 'error', 'message': str(e)}\n\nresult = parse_spr(spr_output)",
                "spr_output": "{{ distill_spr_with_llm.result.generated_text }}"
            },
            "output_variable": "parsed_spr_result",
            "dependencies": ["distill_spr_with_llm"]
        },
        "check_similarity_with_existing_sprs": {
            "action_type": "execute_code",
            "description": "Compares the new SPR with existing SPRs to check for similarity and flag for expedited review.",
            "inputs": {
                "code": "import json\nimport os\nfrom difflib import SequenceMatcher\n\nparsed_result = {{ tasks.parse_and_validate_spr.output.result }}\nif parsed_result.get('status') != 'success':\n    print(json.dumps(parsed_result))\nelse:\n    new_spr = parsed_result['spr_definition']\n    new_desc = new_spr.get('description', '')\n    expedited_review = False\n    similarity_threshold = 0.9\n    \n    try:\n        spr_file_path = 'knowledge_graph/spr_definitions_tv.json'\n        if os.path.exists(spr_file_path):\n            with open(spr_file_path, 'r', encoding='utf-8') as f:\n                existing_sprs = json.load(f)\n            \n            for existing_spr in existing_sprs:\n                existing_desc = existing_spr.get('definition', '')\n                similarity = SequenceMatcher(None, new_desc, existing_desc).ratio()\n                if similarity >= similarity_threshold:\n                    expedited_review = True\n                    new_spr['expedited_review_reason'] = f'High similarity ({similarity:.2f}) to existing SPR: {existing_spr.get(\"spr_id\")}'\n                    break\n        \n        new_spr['expedited_review'] = expedited_review\n        parsed_result['spr_definition'] = new_spr\n        print(json.dumps(parsed_result))\n\n    except Exception as e:\n        parsed_result['status'] = 'error'\n        parsed_result['message'] = f'Similarity check failed: {str(e)}'\n        print(json.dumps(parsed_result))",
                "parsed_spr_result": "{{ tasks.parse_and_validate_spr.output.result }}"
            },
            "output_variable": "final_spr_result",
            "dependencies": ["parse_and_validate_spr"]
        }
    },
    "output": {
        "spr_definition": {
            "value": "{{ final_spr_result.result.spr_definition }}",
            "description": "The newly generated and validated SPR definition."
        },
        "status": {
            "value": "{{ final_spr_result.result.status }}",
            "description": "The final status of the distillation process."
        }
    }
}
