{"content": "TERM: Selenium\n\nDEFINITION:\nA web automation framework that enables browser control and web scraping capabilities. It provides tools for automated web navigation, content extraction, and dynamic web interaction.\n\nBLUEPRINT DETAILS:\nSelenium integration in Four_PointO_ArchE/tools/perception_engine.py with PerceptionEngine class using Selenium WebDriver for advanced web browsing and content extraction.\n\nFULL IMPLEMENTATION CODE (perception_engine.py):\n```python\nfrom typing import Dict, Any, Tuple\nimport os\nimport re\nfrom .utils import create_iar\nfrom .llm_tool import generate_text\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service as ChromeService\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom bs4 import BeautifulSoup\n\nclass PerceptionEngine:\n    \"\"\"\n    An autonomous browsing agent that combines a headless browser\n    with an LLM for intelligent page analysis and interaction.\n    \"\"\"\n    def __init__(self, headless: bool = True):\n        self.driver = self._initialize_driver(headless)\n\n    def _initialize_driver(self, headless: bool = True):\n        \"\"\"Initializes the Selenium WebDriver with enhanced anti-detection measures.\"\"\"\n        options = webdriver.ChromeOptions()\n        \n        # Enhanced anti-detection measures\n        if headless:\n            options.add_argument('--headless=new')  # Use new headless mode\n        options.add_argument('--no-sandbox')\n        options.add_argument('--disable-dev-shm-usage')\n        options.add_argument('--disable-blink-features=AutomationControlled')\n        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n        options.add_experimental_option('useAutomationExtension', False)\n        \n        # More realistic user agent\n        options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n        \n        # Additional stealth options\n        options.add_argument('--disable-web-security')\n        options.add_argument('--allow-running-insecure-content')\n        options.add_argument('--disable-extensions')\n        options.add_argument('--disable-plugins')\n        options.add_argument('--disable-images')  # Faster loading\n        options.add_argument('--disable-javascript')  # Avoid dynamic content issues\n        \n        try:\n            driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n            \n            # Execute script to remove webdriver property\n            driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n            \n            return driver\n        except Exception as e:\n            print(f\"FATAL: Could not initialize WebDriver: {e}\")\n            return None\n\n    def browse_and_summarize(self, url: str) -> str:\n        \"\"\"Navigates to a URL and provides a high-level summary of its content.\"\"\"\n        if not self.driver:\n            return \"WebDriver not initialized.\"\n        \n        try:\n            # Add random delay to appear more human-like\n            import time\n            import random\n            time.sleep(random.uniform(1, 3))\n            \n            self.driver.get(url)\n            self.driver.implicitly_wait(10)\n            \n            # Check if we hit a CAPTCHA or blocking page\n            page_source = self.driver.page_source.lower()\n            if \"captcha\" in page_source or \"unusual traffic\" in page_source or \"blocked\" in page_source:\n                return f'{{\"summary\": \"Access blocked by {url} due to bot detection. The page requires CAPTCHA verification or is blocking automated requests. This is a common issue with search engines and other sites that detect automated browsing.\"}}'\n            \n            # Try to extract search results if it's a Google search\n            if \"google.com/search\" in url:\n                return self._extract_google_search_results()\n            \n            # For other pages, use the original summarization\n            page_content = BeautifulSoup(self.driver.page_source, 'lxml').get_text()\n            \n            # Use the LLM to summarize the raw text content\n            summary_prompt = f\"Please provide a concise summary of the following web page content:\\n\\n{page_content[:4000]}\" # Limit context size\n            \n            llm_inputs = {\"prompt\": summary_prompt, \"model\": \"gemini-1.5-flash\"} # Use a fast model for summarization\n            summary_result, _ = generate_text(llm_inputs)\n            \n            return summary_result.get(\"generated_text\", \"Could not summarize content.\")\n            \n        except Exception as e:\n            return f'{{\"summary\": \"Error accessing {url}: {str(e)}\"}}'\n    \n    def _extract_google_search_results(self) -> str:\n        \"\"\"Extract search results from Google search page.\"\"\"\n        try:\n            # Look for search result elements\n            results = []\n            \n            # Try different selectors for search results\n            selectors = [\n                'div.g',  # Standard Google results\n                'div[data-ved]',  # Alternative selector\n                'div.rc',  # Another common selector\n                'h3'  # Result titles\n            ]\n            \n            for selector in selectors:\n                elements = self.driver.find_elements(\"css selector\", selector)\n                if elements:\n                    for element in elements[:5]:  # Limit to first 5 results\n                        try:\n                            text = element.text.strip()\n                            if text and len(text) > 10:  # Filter out empty or very short results\n                                results.append(text)\n                        except:\n                            continue\n                    break\n            \n            if results:\n                summary = f\"Found {len(results)} search results: \" + \" | \".join(results[:3])\n                return f'{{\"summary\": \"{summary}\"}}'\n            else:\n                return '{\"summary\": \"No search results found on the page. The page may be blocked or the search query did not return results.\"}'\n                \n        except Exception as e:\n            return f'{{\"summary\": \"Error extracting search results: {str(e)}\"}}'\n\n    def navigate(self, url: str):\n        \"\"\"Navigate to a URL.\"\"\"\n        if self.driver:\n            self.driver.get(url)\n            self.driver.implicitly_wait(5)\n\n    def wait_for(self, selector: str):\n        \"\"\"Wait for an element to be present.\"\"\"\n        if self.driver:\n            from selenium.webdriver.common.by import By\n            from selenium.webdriver.support.ui import WebDriverWait\n            from selenium.webdriver.support import expected_conditions as EC\n            try:\n                WebDriverWait(self.driver, 10).until(\n                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n                )\n            except Exception as e:\n                print(f\"Warning: Element {selector} not found: {e}\")\n\n    def extract_text(self, selector: str) -> str:\n        \"\"\"Extract text from elements matching the selector.\"\"\"\n        if not self.driver:\n            return \"\"\n        try:\n            from selenium.webdriver.common.by import By\n            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n            return \" \".join([elem.text for elem in elements if elem.text])\n        except Exception as e:\n            print(f\"Warning: Could not extract text from {selector}: {e}\")\n            return \"\"\n\n    def click(self, selector: str):\n        \"\"\"Click an element matching the selector.\"\"\"\n        if self.driver:\n            try:\n                from selenium.webdriver.common.by import By\n                element = self.driver.find_element(By.CSS_SELECTOR, selector)\n                element.click()\n            except Exception as e:\n                print(f\"Warning: Could not click {selector}: {e}\")\n\n    def type_into(self, selector: str, text: str):\n        \"\"\"Type text into an element matching the selector.\"\"\"\n        if self.driver:\n            try:\n                from selenium.webdriver.common.by import By\n                element = self.driver.find_element(By.CSS_SELECTOR, selector)\n                element.clear()\n                element.send_keys(text)\n            except Exception as e:\n                print(f\"Warning: Could not type into {selector}: {e}\")\n\n    def close(self):\n        \"\"\"Closes the browser.\"\"\"\n        if self.driver:\n            self.driver.quit()\n\n# --- Action Wrapper for the Workflow Engine ---\n\ndef answer_question_from_web(inputs: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"\n    An action that uses the PerceptionEngine to answer a question by browsing the web.\n    This is the first step towards a fully autonomous browsing agent.\n    \"\"\"\n    question = inputs.get(\"question\")\n    if not question:\n        result = {\"error\": \"Missing required input: question.\"}\n        iar = create_iar(0.1, 0.0, [\"Question is required.\"])\n        return result, iar\n        \n    engine = None\n    try:\n        engine = PerceptionEngine()\n        \n        # For this initial implementation, we'll do a simple search and summarize the first result.\n        search_query = question.replace(\" \", \"+\")\n        search_url = f\"https://www.google.com/search?q={search_query}\"\n        \n        summary = engine.browse_and_summarize(search_url)\n\n        # The real power will come from analyzing the search results page and deciding which link to click.\n        # For now, summarizing the results page is a good first step.\n        final_answer_prompt = f\"Based on the following summary of a Google search results page, please provide a direct answer to the user's question.\\n\\nUser Question: '{question}'\\n\\nSearch Summary:\\n{summary}\"\n        \n        llm_inputs = {\"prompt\": final_answer_prompt, \"model\": \"gemini-1.5-pro-latest\"}\n        final_result, _ = generate_text(llm_inputs)\n\n        answer = final_result.get(\"generated_text\", \"Could not derive an answer from the search results.\")\n        \n        result = {\"answer\": answer}\n        iar = create_iar(\n            confidence=0.8,\n            tactical_resonance=0.85,\n            potential_issues=[\"Answer is based on a summary of the first search results page, not a deep dive into links.\"],\n            metadata={\"question\": question}\n        )\n        return result, iar\n\n    except Exception as e:\n        result = {\"error\": f\"An unexpected error occurred in the Perception Engine: {e}\"}\n        iar = create_iar(0.1, 0.1, [f\"Perception Engine Error: {e}\"])\n        return result, iar\n    finally:\n        if engine:\n            engine.close()\n\n```\n\nEXAMPLE APPLICATION:\nSelenium enables the Perception Engine to navigate complex websites, handle dynamic content, bypass CAPTCHA challenges, and extract real-time information for advanced web-based analysis.\n\nCATEGORY: ExternalLibrary\n\nRELATIONSHIPS:\ntype: WebAutomationFramework; enables: Web Automation, Browser Control, Content Extraction; used_by: WebsearcH, Perception Engine, Web Navigation; provides: Browser Drivers, Element Selection, Dynamic Interaction; confidence: high"}