{"content": "TERM: Class: SynergisticInquiryOrchestrator\n\nDEFINITION:\nClass: SynergisticInquiryOrchestrator\n\nOrchestrates the federated search and synthesis process.\n\nMethods: __init__, deconstruct_query, _deconstruct_problem_with_llm, _extract_primary_domain, _generate_targeted_vectors, _optimize_for_search_engines, _get_platform_search_tips, execute_inquiry, synthesize_and_reflect\n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/synergistic_inquiry.py, type: python_class\n\nFULL IMPLEMENTATION CODE (synergistic_inquiry.py):\n```python\n\"\"\"\nSynergistic Inquiry and Synthesis Protocol Orchestrator\n\nThis module implements the core logic for the PhD-level genius search protocol.\nIt deconstructs queries, dispatches tasks to federated agents, and prepares\nthe multi-modal results for final synthesis.\n\nThis architecture aligns with Mandate 4 (The Archeologist) and Mandate 8 (The Crystal).\n\"\"\"\n\nimport logging\nfrom typing import List, Dict, Any\n\nfrom .federated_search_agents import (\n    AcademicKnowledgeAgent,\n    CommunityPulseAgent,\n    CodebaseTruthAgent,\n    VisualSynthesisAgent,\n    SearchEngineAgent\n)\nfrom .synthesis_engine import SynthesisEngine\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\nclass SynergisticInquiryOrchestrator:\n    \"\"\"Orchestrates the federated search and synthesis process.\"\"\"\n    def __init__(self):\n        self.agents = {\n            'academic': AcademicKnowledgeAgent(),\n            'community': CommunityPulseAgent(),\n            'code': CodebaseTruthAgent(),\n            'visual': VisualSynthesisAgent(),\n            'startpage': SearchEngineAgent(\"Startpage\")\n        }\n        self.synthesis_engine = SynthesisEngine()\n        logger.info(\"Synergistic Inquiry Orchestrator initialized with 5 specialized agents and a Synthesis Engine.\")\n\n    def deconstruct_query(self, query: str) -> Dict[str, str]:\n        \"\"\"\n        Deconstructs a user query into targeted vectors for each agent using RISE-inspired methodology.\n        \n        This implementation follows the RISE Knowledge Scaffolding approach:\n        1. Problem deconstruction using LLM\n        2. Domain extraction and analysis\n        3. Targeted query generation for each source type\n        \"\"\"\n        logger.info(f\"Deconstructing query using RISE-inspired methodology: '{query[:100]}...'\")\n        \n        try:\n            # Phase 1: Problem Deconstruction (RISE-inspired)\n            deconstruction = self._deconstruct_problem_with_llm(query)\n            \n            # Phase 2: Domain Extraction\n            primary_domain = self._extract_primary_domain(deconstruction)\n            \n            # Phase 3: Generate targeted vectors for each agent\n            vectors = self._generate_targeted_vectors(query, deconstruction, primary_domain)\n            \n            logger.debug(f\"Generated targeted query vectors: {vectors}\")\n            return vectors\n            \n        except Exception as e:\n            logger.warning(f\"LLM-based deconstruction failed: {e}. Falling back to simple approach.\")\n            # Fallback to simple approach\n            vectors = {\n                'academic': f\"{query} academic review research\",\n                'community': f\"{query} reddit discussion community\",\n                'code': f\"{query} github implementation code\",\n                'visual': f\"{query} youtube tutorial video\",\n                'startpage': f\"{query} best practices latest trends\"\n            }\n            return vectors\n\n    def _deconstruct_problem_with_llm(self, query: str) -> Dict[str, Any]:\n        \"\"\"\n        Deconstruct the problem using LLM analysis (RISE-inspired approach).\n        \"\"\"\n        try:\n            # Use the synthesis engine's LLM for deconstruction\n            deconstruction_prompt = f\"\"\"\n            Analyze the following query and deconstruct it into core components:\n\n            Query: {query}\n\n            IMPORTANT: Preserve the specific domain/topic area in your analysis. Do not focus only on action words like \"analyze\" or \"generate\".\n\n            Identify:\n            1. Core domain areas (the main subject matter/topic)\n            2. Key variables and unknowns  \n            3. Strategic requirements\n            4. Risk factors\n            5. Success criteria\n            6. Search intent (what information is being sought)\n\n            Output your analysis as a structured JSON object with these keys:\n            - core_domains: [list of domain areas - be specific about the topic]\n            - key_variables: [list of variables/unknowns]\n            - strategic_requirements: [list of requirements]\n            - risk_factors: [list of potential risks]\n            - success_criteria: [list of success criteria]\n            - search_intent: [description of what information is being sought]\n            - primary_focus: [the main topic/domain being analyzed, not the action being performed]\n            \"\"\"\n            \n            # Use the synthesis engine's LLM provider\n            llm_response = self.synthesis_engine.llm_provider.generate_chat(\n                messages=[{\"role\": \"user\", \"content\": deconstruction_prompt}],\n                max_tokens=2048,\n                temperature=0.3\n            )\n            \n            # Parse the response\n            if isinstance(llm_response, dict):\n                response_text = llm_response.get(\"generated_text\", \"\")\n            else:\n                response_text = str(llm_response)\n            \n            # Try to extract JSON from the response\n            import json\n            import re\n            \n            # Look for JSON in the response\n            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n            if json_match:\n                try:\n                    return json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    pass\n            \n            # Fallback: create structured response from text\n            return {\n                \"core_domains\": [\"General Analysis\"],\n                \"key_variables\": [\"information\", \"insights\"],\n                \"strategic_requirements\": [\"comprehensive_analysis\"],\n                \"risk_factors\": [\"information_gaps\"],\n                \"success_criteria\": [\"actionable_insights\"],\n                \"search_intent\": \"comprehensive information gathering\",\n                \"primary_focus\": \"General Analysis\",\n                \"raw_response\": response_text\n            }\n            \n        except Exception as e:\n            logger.warning(f\"LLM deconstruction failed: {e}\")\n            return {\n                \"core_domains\": [\"General Analysis\"],\n                \"key_variables\": [\"information\"],\n                \"strategic_requirements\": [\"analysis\"],\n                \"risk_factors\": [\"unknown\"],\n                \"success_criteria\": [\"insights\"],\n                \"search_intent\": \"information gathering\",\n                \"primary_focus\": \"General Analysis\"\n            }\n\n    def _extract_primary_domain(self, deconstruction: Dict[str, Any]) -> str:\n        \"\"\"\n        Extract the primary domain from the deconstruction analysis.\n        \"\"\"\n        primary_focus = deconstruction.get(\"primary_focus\", \"\")\n        core_domains = deconstruction.get(\"core_domains\", [])\n        \n        if primary_focus and primary_focus != \"General Analysis\":\n            return primary_focus\n        \n        if core_domains and len(core_domains) > 0:\n            return core_domains[0]\n        \n        return \"General Analysis\"\n\n    def _generate_targeted_vectors(self, original_query: str, deconstruction: Dict[str, Any], primary_domain: str) -> Dict[str, str]:\n        \"\"\"\n        Generate targeted search vectors for each agent based on deconstruction analysis.\n        \"\"\"\n        search_intent = deconstruction.get(\"search_intent\", \"information gathering\")\n        key_variables = deconstruction.get(\"key_variables\", [])\n        \n        # Create targeted vectors for each agent type\n        vectors = {}\n        \n        # Academic Agent: Focus on research, papers, studies\n        academic_terms = [\"research\", \"study\", \"analysis\", \"academic\", \"paper\", \"journal\"]\n        if primary_domain != \"General Analysis\":\n            academic_query = f\"{primary_domain} {' '.join(academic_terms[:3])}\"\n        else:\n            # Use much more of the original query for robust, accurate results\n            academic_query = f\"{original_query[:800]} {' '.join(academic_terms[:2])}\"\n        vectors['academic'] = academic_query\n        \n        # Community Agent: Focus on discussions, opinions, real-world experiences\n        community_terms = [\"discussion\", \"opinion\", \"experience\", \"community\", \"reddit\", \"forum\"]\n        if primary_domain != \"General Analysis\":\n            community_query = f\"{primary_domain} {' '.join(community_terms[:3])}\"\n        else:\n            # Use much more of the original query for robust, accurate results\n            community_query = f\"{original_query[:800]} {' '.join(community_terms[:2])}\"\n        vectors['community'] = community_query\n        \n        # Code Agent: Focus on implementations, repositories, technical solutions\n        code_terms = [\"implementation\", \"code\", \"github\", \"repository\", \"technical\", \"solution\"]\n        if primary_domain != \"General Analysis\":\n            code_query = f\"{primary_domain} {' '.join(code_terms[:3])}\"\n        else:\n            # Use much more of the original query for robust, accurate results\n            code_query = f\"{original_query[:800]} {' '.join(code_terms[:2])}\"\n        vectors['code'] = code_query\n        \n        # Visual Agent: Focus on tutorials, demonstrations, visual content\n        visual_terms = [\"tutorial\", \"demo\", \"video\", \"youtube\", \"explanation\", \"guide\"]\n        if primary_domain != \"General Analysis\":\n            visual_query = f\"{primary_domain} {' '.join(visual_terms[:3])}\"\n        else:\n            # Use much more of the original query for robust, accurate results\n            visual_query = f\"{original_query[:800]} {' '.join(visual_terms[:2])}\"\n        vectors['visual'] = visual_query\n        \n        # Search Engine Agent: Use optimized query for Startpage (working)\n        search_engine_query = self._optimize_for_search_engines(original_query, primary_domain, deconstruction)\n        vectors['startpage'] = search_engine_query\n        \n        return vectors\n\n    def _optimize_for_search_engines(self, original_query: str, primary_domain: str, deconstruction: Dict[str, Any]) -> str:\n        \"\"\"\n        Optimize search queries specifically for search engines using platform-specific techniques.\n        \"\"\"\n        # Get platform-specific search tips\n        search_tips = self._get_platform_search_tips()\n        \n        # Build optimized query\n        optimized_parts = []\n        \n        # Add primary domain if available\n        if primary_domain != \"General Analysis\":\n            optimized_parts.append(primary_domain)\n        else:\n            # For general analysis, use more of the original query to preserve context\n            optimized_parts.append(original_query[:600])  # Use significant portion of original query\n        \n        # Add key terms from deconstruction\n        key_variables = deconstruction.get(\"key_variables\", [])\n        if key_variables:\n            optimized_parts.extend(key_variables[:4])  # Increased from 2 to 4 for more context\n        \n        # Add search optimization terms\n        optimization_terms = search_tips.get(\"general_optimization\", [])\n        if optimization_terms:\n            optimized_parts.extend(optimization_terms[:2])\n        \n        # Fallback to truncated original query\n        if not optimized_parts:\n            optimized_parts.append(original_query[:800])  # Increased significantly for robust results\n        \n        return \" \".join(optimized_parts)\n\n    def _get_platform_search_tips(self) -> Dict[str, List[str]]:\n        \"\"\"\n        Get platform-specific search optimization tips and techniques.\n        This could be enhanced by searching for current best practices.\n        \"\"\"\n        return {\n            \"general_optimization\": [\n                \"best practices\",\n                \"latest trends\",\n                \"comprehensive guide\",\n                \"expert insights\"\n            ],\n            \"academic_optimization\": [\n                \"research paper\",\n                \"peer reviewed\",\n                \"academic study\",\n                \"scientific analysis\"\n            ],\n            \"community_optimization\": [\n                \"real world experience\",\n                \"community discussion\",\n                \"user feedback\",\n                \"practical advice\"\n            ],\n            \"code_optimization\": [\n                \"open source\",\n                \"implementation\",\n                \"code example\",\n                \"technical solution\"\n            ],\n            \"visual_optimization\": [\n                \"step by step tutorial\",\n                \"visual demonstration\",\n                \"hands on guide\",\n                \"practical example\"\n            ]\n        }\n\n    def execute_inquiry(self, query: str, max_results_per_agent: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"\n        Executes the full Synergistic Inquiry and Synthesis Protocol.\n        \n        Phase 1: Query Deconstruction\n        Phase 2: Federated, Source-Aware Inquiry\n        \"\"\"\n        # Phase 1: Deconstruct the query\n        query_vectors = self.deconstruct_query(query)\n        \n        # Phase 2: Execute inquiry across federated agents in parallel (conceptually)\n        all_results = []\n        for agent_type, agent_query in query_vectors.items():\n            agent = self.agents.get(agent_type)\n            if agent:\n                try:\n                    results = agent.search(agent_query, max_results=max_results_per_agent)\n                    logger.info(f\"Agent '{agent.name}' found {len(results)} results.\")\n                    all_results.extend(results)\n                except Exception as e:\n                    logger.error(f\"Agent '{agent.name}' failed during search: {e}\")\n            else:\n                logger.warning(f\"No agent found for type: {agent_type}\")\n        \n        logger.info(f\"Synergistic inquiry complete. Total results gathered: {len(all_results)}\")\n        return all_results\n\n    def synthesize_and_reflect(self, query: str, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"\n        Phase 3 & 4: Invokes the Synthesis Engine to perform deep synthesis and reflection.\n        \"\"\"\n        logger.info(\"Handing off to Synthesis Engine for final processing.\")\n        return self.synthesis_engine.synthesize(query, results)\n\n```\n\nEXAMPLE APPLICATION:\nClass: SynergisticInquiryOrchestrator\n\nOrchestrates the federated search and synthesis process.\n\nMethods: __init__, deconstruct_query, _deconstruct_problem_with_llm, _extract_primary_domain, _generate_targeted_vectors, _optimize_for_search_engines, _get_platform_search_tips, execute_inquiry, synthesize_and_reflect\n\nCATEGORY: CodeKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/synergistic_inquiry.py; source_type: python_class"}