{"content": "TERM: Function: main\n\nDEFINITION:\nFunction: main\n\nMain entry point for cron job\n\nParameters: \n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/nfl_automated_data_gatherer.py, type: python_function\n\nFULL IMPLEMENTATION CODE (nfl_automated_data_gatherer.py):\n```python\n#!/usr/bin/env python3\n\"\"\"\nAutomated NFL Data Gatherer\nRuns via cron jobs to collect data without user interaction\n\"\"\"\n\nimport logging\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport json\n\n# Add parent directory to path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\nfrom Three_PointO_ArchE.nfl_insider_database import NFLInsiderDatabase\nfrom Three_PointO_ArchE.nfl_insider_intelligence import NFLInsiderIntelligence\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('logs/nfl_data_gatherer.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\nclass AutomatedDataGatherer:\n    \"\"\"Automated data gathering system\"\"\"\n    \n    def __init__(self):\n        self.db = NFLInsiderDatabase()\n        self.insider_intel = NFLInsiderIntelligence()\n    \n    def gather_transactions(self):\n        \"\"\"Gather player/coach transactions from NFL.com\"\"\"\n        logger.info(\"Starting transaction gathering...\")\n        \n        try:\n            # This would scrape NFL.com transactions\n            # For now, using placeholder logic\n            from Three_PointO_ArchE.nfl_transaction_scraper import scrape_nfl_transactions\n            \n            today = datetime.now()\n            transactions = scrape_nfl_transactions(today.year, today.month)\n            \n            new_count = 0\n            for trans in transactions:\n                movement_id = self.db.add_player_movement(\n                    player_name=trans['player_name'],\n                    from_team=trans['from_team'],\n                    to_team=trans['to_team'],\n                    transaction_date=trans['date'],\n                    transaction_type=trans['type'],\n                    role=trans.get('role', 'player'),\n                    position=trans.get('position'),\n                    years_with_team=trans.get('years', 0),\n                    current_status=trans.get('status', 'active')\n                )\n                if movement_id:\n                    new_count += 1\n            \n            self.db.update_data_source('nfl_com_transactions', 'active')\n            logger.info(f\"Gathered {new_count} new transactions\")\n            \n        except Exception as e:\n            logger.error(f\"Transaction gathering failed: {e}\")\n            self.db.update_data_source('nfl_com_transactions', 'error', str(e))\n            self.db.create_alert('data_gathering_error', 'high', \n                                f\"Transaction gathering failed: {e}\")\n    \n    def gather_betting_lines(self):\n        \"\"\"Gather betting line data\"\"\"\n        logger.info(\"Starting betting line gathering...\")\n        \n        try:\n            # This would fetch from The Odds API or scrape Vegas Insider\n            from Three_PointO_ArchE.nfl_betting_line_fetcher import fetch_betting_lines\n            \n            lines = fetch_betting_lines()\n            \n            # Store in database (would need betting_lines table)\n            # For now, just log\n            logger.info(f\"Gathered {len(lines)} betting lines\")\n            self.db.update_data_source('betting_lines', 'active')\n            \n        except Exception as e:\n            logger.error(f\"Betting line gathering failed: {e}\")\n            self.db.update_data_source('betting_lines', 'error', str(e))\n    \n    def gather_injury_reports(self):\n        \"\"\"Gather injury reports\"\"\"\n        logger.info(\"Starting injury report gathering...\")\n        \n        try:\n            from Three_PointO_ArchE.nfl_injury_scraper import scrape_injury_reports\n            \n            week = self._get_current_week()\n            injuries = scrape_injury_reports(week)\n            \n            # Store injuries (would need injuries table)\n            logger.info(f\"Gathered {len(injuries)} injury reports\")\n            self.db.update_data_source('injury_reports', 'active')\n            \n        except Exception as e:\n            logger.error(f\"Injury report gathering failed: {e}\")\n            self.db.update_data_source('injury_reports', 'error', str(e))\n    \n    def check_for_alerts(self):\n        \"\"\"Check for high-priority alerts and send notifications\"\"\"\n        alerts = self.db.get_pending_alerts(priority='high')\n        \n        if alerts:\n            logger.warning(f\"Found {len(alerts)} high-priority alerts\")\n            # Send notification (email, Slack, etc.)\n            self._send_notification(alerts)\n    \n    def _get_current_week(self) -> int:\n        \"\"\"Calculate current NFL week\"\"\"\n        # NFL season typically starts first week of September\n        season_start = datetime(2025, 9, 4)  # Adjust for actual season start\n        today = datetime.now()\n        week = ((today - season_start).days // 7) + 1\n        return min(week, 18)  # Max 18 weeks\n    \n    def _send_notification(self, alerts: list):\n        \"\"\"Send notification about alerts\"\"\"\n        # Could send email, Slack message, etc.\n        # For now, just log\n        for alert in alerts:\n            logger.warning(f\"ALERT [{alert['priority']}]: {alert['message']}\")\n    \n    def run_daily_gathering(self):\n        \"\"\"Run all daily data gathering tasks\"\"\"\n        logger.info(\"=\" * 60)\n        logger.info(\"Starting daily NFL data gathering\")\n        logger.info(\"=\" * 60)\n        \n        self.gather_transactions()\n        self.gather_betting_lines()\n        self.gather_injury_reports()\n        self.check_for_alerts()\n        \n        logger.info(\"Daily gathering complete\")\n    \n    def run_weekly_gathering(self):\n        \"\"\"Run weekly data gathering tasks\"\"\"\n        logger.info(\"=\" * 60)\n        logger.info(\"Starting weekly NFL data gathering\")\n        logger.info(\"=\" * 60)\n        \n        # Update practice squad rosters\n        # Update coaching staff changes\n        # Update advanced metrics\n        \n        logger.info(\"Weekly gathering complete\")\n    \n    def close(self):\n        \"\"\"Cleanup\"\"\"\n        self.db.close()\n\n\ndef main():\n    \"\"\"Main entry point for cron job\"\"\"\n    gatherer = AutomatedDataGatherer()\n    \n    try:\n        # Determine what to run based on day of week\n        today = datetime.now().weekday()\n        \n        if today == 0:  # Monday - Weekly tasks\n            gatherer.run_weekly_gathering()\n        else:  # Daily tasks\n            gatherer.run_daily_gathering()\n            \n    except Exception as e:\n        logger.error(f\"Data gathering failed: {e}\", exc_info=True)\n        gatherer.db.create_alert('system_error', 'high', f\"Data gathering system error: {e}\")\n    finally:\n        gatherer.close()\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n```\n\nEXAMPLE APPLICATION:\nFunction: main\n\nMain entry point for cron job\n\nParameters: \n\nCATEGORY: CodeKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/nfl_automated_data_gatherer.py; source_type: python_function"}