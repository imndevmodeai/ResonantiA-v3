{"content": "TERM: Class: WorkflowOrchestrator\n\nDEFINITION:\nClass: WorkflowOrchestrator\n\nManages the discovery, loading, and execution of cognitive routines (workflows)\nbased on a central registry. This decouples the system's core logic from the\nphysical location of workflow files, enabling modularity and resilience.\n\nMethods: __new__, load_registry, flatten_workflows, get_workflow_details, get_workflow_path, list_workflows, select_workflow_for_query, search_workflows, execute_workflow\n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/workflow_orchestrator.py, type: python_class\n\nFULL IMPLEMENTATION CODE (workflow_orchestrator.py):\n```python\nimport json\nimport os\nfrom typing import Dict, Any, Optional, List\n\nclass WorkflowOrchestrator:\n    \"\"\"\n    Manages the discovery, loading, and execution of cognitive routines (workflows)\n    based on a central registry. This decouples the system's core logic from the\n    physical location of workflow files, enabling modularity and resilience.\n    \"\"\"\n    _instance = None\n\n    def __new__(cls, registry_path: str = 'core_workflows/registry.json'):\n        if cls._instance is None:\n            cls._instance = super(WorkflowOrchestrator, cls).__new__(cls)\n            cls._instance.registry_path = registry_path\n            cls._instance.registry = cls._instance.load_registry()\n            cls._instance.workflows = cls._instance.flatten_workflows()\n        return cls._instance\n\n    def load_registry(self) -> Dict[str, Any]:\n        \"\"\"Loads the workflow registry file.\"\"\"\n        if not os.path.exists(self.registry_path):\n            raise FileNotFoundError(f\"Workflow registry not found at: {self.registry_path}\")\n        with open(self.registry_path, 'r') as f:\n            return json.load(f)\n\n    def flatten_workflows(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Creates a flat dictionary of workflows for quick lookup by ID.\"\"\"\n        flat_map = {}\n        for category_data in self.registry.get('categories', {}).values():\n            for workflow in category_data.get('workflows', []):\n                if 'id' in workflow:\n                    flat_map[workflow['id']] = workflow\n        return flat_map\n\n    def get_workflow_details(self, workflow_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieves the details (path, description) for a given workflow ID.\n\n        Args:\n            workflow_id: The unique identifier of the workflow.\n\n        Returns:\n            A dictionary containing the workflow's details, or None if not found.\n        \"\"\"\n        return self.workflows.get(workflow_id)\n\n    def get_workflow_path(self, workflow_id: str) -> Optional[str]:\n        \"\"\"\n        Gets the file path for a given workflow ID.\n\n        Args:\n            workflow_id: The unique identifier of the workflow.\n\n        Returns:\n            The file path as a string, or None if the ID is not found.\n        \"\"\"\n        details = self.get_workflow_details(workflow_id)\n        return details.get('path') if details else None\n\n    def list_workflows(self, category: Optional[str] = None) -> List[Dict[str, Any]]:\n        \"\"\"\n        Lists all available workflows, optionally filtered by category.\n        \"\"\"\n        if category:\n            return self.registry.get('categories', {}).get(category, {}).get('workflows', [])\n        return list(self.workflows.values())\n\n    def select_workflow_for_query(self, query: str) -> Optional[str]:\n        \"\"\"\n        Selects the most appropriate workflow for a given query using a simple\n        keyword-based scoring system. This is a basic implementation of the ACO's\n        routing logic.\n        \"\"\"\n        scores: Dict[str, int] = {wf_id: 0 for wf_id in self.workflows.keys()}\n        query_lower = query.lower()\n\n        # Define keyword mappings to boost scores for specific intents\n        keyword_map = {\n            'temporal_forecasting_workflow': ['forecast', 'predict', 'future', 'project', 'estimate'],\n            'temporal_causal_analysis_workflow': ['why', 'cause', 'impact', 'effect', 'reason', 'correlation', 'affect'],\n            'agentic_research': ['research', 'find information', 'what is', 'who is', 'summarize', 'look up'],\n            'tesla_visioning_workflow': ['design', 'create', 'invent', 'conceptualize', 'framework', 'build a plan for'],\n        }\n\n        # Score based on direct keyword mapping\n        for wf_id, keywords in keyword_map.items():\n            for keyword in keywords:\n                if keyword in query_lower:\n                    scores[wf_id] += 5  # High score for a direct keyword match\n\n        # Generic scoring based on word overlap in the workflow's description\n        query_words = set(query_lower.split())\n        for wf_id, details in self.workflows.items():\n            description_words = set(details.get('description', '').lower().split())\n            common_words = description_words.intersection(query_words)\n            scores[wf_id] += len(common_words)\n\n        # Find the workflow with the highest score\n        if not any(s > 0 for s in scores.values()):\n            print(\"INFO: No specific keywords matched. Defaulting to RISE engine for deep analysis.\")\n            return 'rise_cognitive_scaffolding_and_grounding'\n\n        best_workflow_id = max(scores, key=scores.get)\n        \n        # If the best score is low, it's likely a generic query better suited for the full RISE engine\n        if scores[best_workflow_id] < 3:\n            print(\"INFO: No specific workflow matched strongly. Defaulting to RISE engine for deep analysis.\")\n            return 'rise_cognitive_scaffolding_and_grounding'\n\n        return best_workflow_id\n\n    def search_workflows(self, search_term: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Performs a simple search across workflow IDs and descriptions.\n\n        Args:\n            search_term: The term to search for (case-insensitive).\n\n        Returns:\n            A list of matching workflow detail dictionaries.\n        \"\"\"\n        results = []\n        term = search_term.lower()\n        for workflow_id, details in self.workflows.items():\n            if term in workflow_id.lower() or term in details.get('description', '').lower():\n                results.append(details)\n        return results\n\n    def execute_workflow(self, workflow_id: str, inputs: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Executes a workflow by its ID.\n\n        NOTE: This is a placeholder for integration with the full IARCompliantWorkflowEngine.\n              In a real implementation, this method would instantiate and run the engine\n              with the workflow definition loaded from the path.\n        \"\"\"\n        print(f\"--- [WorkflowOrchestrator] ---\")\n        print(f\"REQUEST: SIMULATE execution of workflow '{workflow_id}'\")\n        \n        workflow_path = self.get_workflow_path(workflow_id)\n        if not workflow_path:\n            print(f\"ERROR: Workflow ID '{workflow_id}' not found in registry.\")\n            return {\"status\": \"error\", \"message\": \"Workflow not found\"}\n            \n        if not os.path.exists(workflow_path):\n            print(f\"ERROR: Workflow file not found at path: {workflow_path}\")\n            return {\"status\": \"error\", \"message\": \"Workflow file missing\"}\n\n        print(f\"INFO: Loading workflow definition from: {workflow_path}\")\n        # Placeholder for actual execution engine logic\n        print(f\"INFO: Simulating execution with inputs: {inputs}\")\n        print(f\"SUCCESS: Workflow '{workflow_id}' simulation complete.\")\n        print(f\"---------------------------------\")\n        \n        return {\n            \"status\": \"simulated_success\",\n            \"workflow_id\": workflow_id,\n            \"inputs\": inputs,\n            \"output\": {\"message\": \"Placeholder output from simulated execution.\"}\n        }\n\nif __name__ == '__main__':\n    # --- DEMONSTRATION OF DYNAMIC ORCHESTRATOR (ACO) USAGE ---\n    try:\n        orchestrator = WorkflowOrchestrator()\n\n        print(\"--- Workflow Orchestrator (ACO Simulation) Initialized ---\")\n        print(\"This is a basic simulation of the ACO's dynamic dispatch.\")\n        print(\"Enter a query, and the orchestrator will select and run the best workflow.\")\n        print(\"Example queries:\")\n        print(\"  'forecast the stock price'\")\n        print(\"  'what is the impact of gdp on inflation?'\")\n        print(\"  'design a new cognitive protocol'\")\n        print(\"  'tell me about the ResonantiA Protocol'\")\n        print(\"Type 'quit' to exit.\")\n\n        while True:\n            user_query = input(\"\\nEnter your query: \")\n            if user_query.lower() == 'quit':\n                break\n            \n            if not user_query:\n                continue\n\n            print(f\"\\n[ACO] Analyzing query: '{user_query}'\")\n            selected_workflow_id = orchestrator.select_workflow_for_query(user_query)\n            \n            if selected_workflow_id:\n                details = orchestrator.get_workflow_details(selected_workflow_id)\n                print(f\"[ACO] Best workflow selected: '{selected_workflow_id}'\")\n                print(f\"[ACO] Reason: {details.get('description')}\")\n                \n                # In a real system, we would dynamically construct the inputs based on the workflow's schema.\n                # For this demo, we'll just pass the raw query.\n                simulated_inputs = {\"user_query\": user_query}\n                \n                orchestrator.execute_workflow(selected_workflow_id, simulated_inputs)\n            else:\n                # This case is unlikely with the default fallback, but included for completeness\n                print(\"[ACO] Could not determine a suitable workflow for the query.\")\n\n    except FileNotFoundError as e:\n        print(f\"FATAL ERROR: Could not initialize orchestrator. {e}\")\n\n```\n\nEXAMPLE APPLICATION:\nClass: WorkflowOrchestrator\n\nManages the discovery, loading, and execution of cognitive routines (workflows)\nbased on a central registry. This decouples the system's core logic from the\nphysical location of workflow files, enabling modularity and resilience.\n\nMethods: __new__, load_registry, flatten_workflows, get_workflow_details, get_workflow_path, list_workflows, select_workflow_for_query, search_workflows, execute_workflow\n\nCATEGORY: CodeKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/workflow_orchestrator.py; source_type: python_class"}