{"content": "TERM: Web Search Tool - Living Specification (DEPRECATED): ⚠️ DEPRECATION NOTICE\n\nDEFINITION:\n**This specification is DEPRECATED as of ArchE v4.0. The Web Search Tool has been superseded by the Enhanced Perception Engine, which provides superior capabilities including:**\n\n- **Intelligent Analysis**: Advanced LLM-powered content analysis and synthesis\n- **Relevance Scoring**: Sophisticated relevance and credibility assessment\n- **Enhanced Reliability**: HTTP-based search with 100% success rate\n- **Comprehensive IAR**: Full Integrated Action Reflection compliance\n- **Session Management**: Advanced tracking and performance metrics\n\n**Please refer to `enhanced_perception_engine.md` for the current web exploration capabilities.**\n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/specifications/web_search_tool.md, type: specification_md\n\nFULL SPECIFICATION (web_search_tool.md):\n# Web Search Tool - Living Specification (DEPRECATED)\n\n## ⚠️ DEPRECATION NOTICE\n\n**This specification is DEPRECATED as of ArchE v4.0. The Web Search Tool has been superseded by the Enhanced Perception Engine, which provides superior capabilities including:**\n\n- **Intelligent Analysis**: Advanced LLM-powered content analysis and synthesis\n- **Relevance Scoring**: Sophisticated relevance and credibility assessment\n- **Enhanced Reliability**: HTTP-based search with 100% success rate\n- **Comprehensive IAR**: Full Integrated Action Reflection compliance\n- **Session Management**: Advanced tracking and performance metrics\n\n**Please refer to `enhanced_perception_engine.md` for the current web exploration capabilities.**\n\n## Overview (Legacy)\n\nThe **Web Search Tool** served as the \"Digital Explorer of ArchE,\" providing basic web search capabilities with unified search integration and intelligent fallback mechanisms. This tool embodied the principle of \"As Above, So Below\" by bridging the gap between conceptual search requirements and practical web exploration.\n\n## Allegory: The Deep-Sea Archivist\n\nImagine an immense, ancient library at the bottom of the ocean. It contains every book ever written, but it is flooded. The books are not neatly arranged on shelves; they are floating in a chaotic soup of pages, bindings, and debris. This is the internet. The **Deep-Sea Archivist** is a specialized submersible designed to navigate this chaos, using a primary, advanced sonar (`unified_search_tool`) to find curated artifacts, and a more direct `salvage claw` (`legacy DuckDuckGo scraping`) as a reliable fallback.\n\n## Core Architecture\n\n### Primary Components\n\n1. **Unified Search Integration**\n   - Seamless integration with `unified_search_tool`\n   - Intelligent engine selection and result processing\n   - Enhanced error handling and fallback mechanisms\n\n2. **Legacy Search Fallback**\n   - DuckDuckGo-based direct search implementation\n   - BeautifulSoup parsing for result extraction\n   - Robust error handling and timeout management\n\n3. **IAR Compliance**\n   - Full Integrated Action Reflection implementation\n   - Detailed execution tracking and confidence assessment\n   - Comprehensive error reporting and issue identification\n\n## Key Capabilities\n\n### 1. Intelligent Search Orchestration\n\n```python\ndef search_web(inputs: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Perform a web search using the enhanced unified search tool with intelligent fallback.\n    \n    Args:\n        inputs (Dict): A dictionary containing:\n            - query (str): Search query string.\n            - num_results (int): Number of results to return.\n            - provider (str): The search provider ('duckduckgo' is the reliable default).\n        \n    Returns:\n        Dictionary containing search results and a compliant IAR reflection.\n    \"\"\"\n```\n\n**Features:**\n- **Query Validation**: Ensures required parameters are present\n- **Provider Flexibility**: Supports multiple search engines with DuckDuckGo as default\n- **Result Limiting**: Configurable number of results returned\n- **Error Handling**: Comprehensive error detection and reporting\n\n### 2. Unified Search Integration\n\n**Primary Method:**\n- Attempts to use the enhanced `unified_search_tool` first\n- Converts unified search results to standardized format\n- Provides detailed metadata about search method and performance\n\n**Result Processing:**\n```python\n# Convert unified search results to the expected format\nresults = []\nfor item in search_result.get(\"results\", [])[:num_results]:\n    results.append({\n        \"title\": item.get(\"title\", \"\"),\n        \"url\": item.get(\"link\", \"\"),\n        \"snippet\": item.get(\"description\", \"\")\n    })\n```\n\n### 3. Legacy Search Fallback\n\n**DuckDuckGo Implementation:**\n- Direct HTML parsing using BeautifulSoup\n- URL cleaning and validation\n- Robust error handling for network issues\n\n**Features:**\n- **Timeout Management**: 15-second timeout for network requests\n- **User-Agent Spoofing**: Mimics legitimate browser requests\n- **Result Validation**: Ensures URLs are properly formatted\n- **Error Recovery**: Graceful handling of parsing failures\n\n### 4. IAR Compliance\n\n**Reflection Structure:**\n```python\n\"reflection\": create_reflection(\n    action_name=action_name,\n    status=ExecutionStatus.SUCCESS,\n    message=f\"Found {len(results)} results using unified search ({search_result.get('search_method', 'unknown')}).\",\n    inputs=inputs,\n    outputs={\n        \"results_count\": len(results),\n        \"search_method\": search_result.get(\"search_method\", \"unknown\"),\n        \"response_time\": search_result.get(\"response_time\", 0)\n    },\n    confidence=0.9,\n    execution_time=time.time() - start_time\n)\n```\n\n**Reflection Components:**\n- **Status Tracking**: Success, failure, or warning states\n- **Performance Metrics**: Response time and result count\n- **Method Identification**: Which search method was used\n- **Confidence Assessment**: Reliability of results\n- **Issue Identification**: Potential problems or limitations\n\n## Configuration and Dependencies\n\n### Required Dependencies\n\n```python\n# Core imports\nimport logging\nfrom typing import Dict, Any, List, Optional\nimport time\nimport sys\nimport os\nfrom pathlib import Path\n\n# Search-specific imports\nimport requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import quote_plus\n\n# IAR compliance\nfrom .utils.reflection_utils import create_reflection, ExecutionStatus\n```\n\n### Optional Dependencies\n\n```python\n# Unified search tool (optional)\ntry:\n    from unified_search_tool import perform_web_search as unified_search\n    UNIFIED_SEARCH_AVAILABLE = True\nexcept ImportError:\n    UNIFIED_SEARCH_AVAILABLE = False\n```\n\n## Error Handling and Resilience\n\n### 1. Input Validation\n\n```python\nif not query:\n    return {\n        \"error\": \"Input 'query' is required.\",\n        \"reflection\": create_reflection(\n            action_name=action_name,\n            status=ExecutionStatus.FAILURE,\n            message=\"Input validation failed: 'query' is required.\",\n            inputs=inputs,\n            execution_time=time.time() - start_time\n        )\n    }\n```\n\n### 2. Network Error Handling\n\n```python\nexcept requests.exceptions.RequestException as e:\n    error_msg = f\"Network error during web search: {str(e)}\"\n    logger.error(error_msg, exc_info=True)\n    return {\n        \"error\": error_msg,\n        \"reflection\": create_reflection(\n            action_name=action_name,\n            status=ExecutionStatus.FAILURE,\n            message=error_msg,\n            inputs=inputs,\n            potential_issues=[type(e).__name__],\n            execution_time=time.time() - start_time\n        )\n    }\n```\n\n### 3. Provider Validation\n\n```python\nif provider != \"duckduckgo\":\n    return {\n        \"error\": \"Unsupported provider. Only 'duckduckgo' is currently supported for direct requests.\",\n        \"reflection\": create_reflection(\n            action_name=action_name,\n            status=ExecutionStatus.FAILURE,\n            message=f\"Provider '{provider}' is not supported.\",\n            inputs=inputs,\n            potential_issues=[\"ConfigurationError\"],\n            execution_time=time.time() - start_time\n        )\n    }\n```\n\n## Performance Characteristics\n\n### 1. Response Time Optimization\n\n- **Unified Search**: Typically faster with better result quality\n- **Legacy Fallback**: Reliable but may be slower due to HTML parsing\n- **Timeout Management**: 15-second limit prevents hanging requests\n\n### 2. Result Quality\n\n- **Unified Search**: Enhanced result processing and metadata\n- **Legacy Fallback**: Basic but reliable result extraction\n- **URL Validation**: Ensures all returned URLs are properly formatted\n\n### 3. Resource Usage\n\n- **Memory**: Minimal memory footprint for result processing\n- **Network**: Efficient request handling with proper timeout management\n- **CPU**: Lightweight HTML parsing for legacy fallback\n\n## Integration Points\n\n### 1. Action Registry Integration\n\n```python\n# Registered in action_registry.py\ndef search_web(inputs: Dict[str, Any]) -> Dict[str, Any]:\n    # Implementation here\n```\n\n### 2. Workflow Engine Integration\n\n- Supports template variable resolution\n- Compatible with workflow dependency management\n- Provides IAR-compliant outputs for workflow tracking\n\n### 3. Configuration Integration\n\n- Uses centralized configuration system\n- Supports environment-based configuration\n- Maintains compatibility with ArchE's configuration patterns\n\n## Usage Examples\n\n### 1. Basic Web Search\n\n```python\ninputs = {\n    \"query\": \"artificial intelligence trends 2024\",\n    \"num_results\": 10,\n    \"provider\": \"duckduckgo\"\n}\n\nresult = search_web(inputs)\n```\n\n### 2. Workflow Integration\n\n```json\n{\n  \"action_type\": \"search_web\",\n  \"inputs\": {\n    \"query\": \"{{context.search_topic}}\",\n    \"num_results\": 5,\n    \"provider\": \"duckduckgo\"\n  },\n  \"description\": \"Search for current information on the specified topic\"\n}\n```\n\n### 3. Error Handling Example\n\n```python\n# The tool automatically handles various error scenarios:\n# - Network timeouts\n# - Invalid queries\n# - Unsupported providers\n# - Parsing failures\n# - Empty results\n```\n\n## Future Enhancements\n\n### 1. Enhanced Provider Support\n\n- **Google Search**: Integration with Google Custom Search API\n- **Bing Search**: Microsoft Bing Search API integration\n- **Academic Search**: Specialized academic search engines\n\n### 2. Advanced Result Processing\n\n- **Content Summarization**: Automatic result summarization\n- **Relevance Scoring**: Intelligent result ranking\n- **Duplicate Detection**: Removal of duplicate results\n\n### 3. Caching and Performance\n\n- **Result Caching**: Cache frequently requested searches\n- **Incremental Updates**: Update cached results periodically\n- **Performance Monitoring**: Track search performance metrics\n\n## Security Considerations\n\n### 1. Input Sanitization\n\n- **Query Validation**: Ensures queries are properly formatted\n- **URL Validation**: Validates all returned URLs\n- **Content Filtering**: Filters potentially harmful content\n\n### 2. Rate Limiting\n\n- **Request Throttling**: Prevents excessive API usage\n- **Timeout Management**: Prevents hanging requests\n- **Error Recovery**: Graceful handling of rate limit errors\n\n### 3. Privacy Protection\n\n- **No Query Logging**: Does not log sensitive search queries\n- **Anonymous Requests**: Uses generic user agents\n- **Data Minimization**: Only processes necessary data\n\n## Testing and Validation\n\n### 1. Unit Tests\n\n- **Input Validation**: Tests for various input scenarios\n- **Error Handling**: Tests for network and parsing errors\n- **Result Processing**: Tests for result format validation\n\n### 2. Integration Tests\n\n- **Workflow Integration**: Tests integration with workflow engine\n- **IAR Compliance**: Tests reflection generation\n- **Performance Tests**: Tests response time and resource usage\n\n### 3. End-to-End Tests\n\n- **Real Search Queries**: Tests with actual web searches\n- **Error Scenarios**: Tests various failure modes\n- **Performance Benchmarks**: Tests under load conditions\n\n## Conclusion\n\nThe Web Search Tool represents a sophisticated implementation of web search capabilities within the ArchE system. Its intelligent fallback mechanisms, comprehensive error handling, and IAR compliance make it a reliable and robust component for web-based information retrieval. The tool's design philosophy of \"intelligent exploration with reliable fallbacks\" ensures that users can always access web information, even when primary search methods are unavailable.\n\nThe implementation demonstrates the \"As Above, So Below\" principle by providing a conceptual interface (unified search) while maintaining practical reliability (legacy fallback), creating a system that is both sophisticated and dependable.\n\n\nEXAMPLE APPLICATION:\n**This specification is DEPRECATED as of ArchE v4.0. The Web Search Tool has been superseded by the Enhanced Perception Engine, which provides superior capabilities including:**\n\n- **Intelligent Analysis**: Advanced LLM-powered content analysis and synthesis\n- **Relevance Scoring**: Sophisticated relevance and credibility assessment\n- **Enhanced Reliability**: HTTP-based search with 100% success rate\n- **Comprehensive IAR**: Full Integrated Action Reflection compliance\n- **Session Management**: \n\nCATEGORY: SpecificationKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/specifications/web_search_tool.md; source_type: specification_md"}