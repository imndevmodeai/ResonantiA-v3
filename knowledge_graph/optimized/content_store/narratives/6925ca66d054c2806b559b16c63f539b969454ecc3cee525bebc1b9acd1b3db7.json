{"content": "TERM: The Foundation Forge: Knowledge Scaffolding Workflow: Task 6: `forge_specialist_agent`\n\nDEFINITION:\n**Purpose**: Create the Specialized Cognitive Agent (SCA)\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nCreate a specialized agent profile for solving this problem:\n\nProblem: {problem_description}\nRequirements: {analyze_specialization_requirements.result.generated_text}\n\nDefine:\n1. Agent's core expertise and background\n2. Analytical frameworks and methodologies\n3. Strategic thinking patterns\n4. Risk assessment capabilities\n5. Implementation approach\n6. Success metrics and validation criteria\n```\n\n**Model Settings**:\n- `temperature`: 0.3 (structured agent creation)\n- `max_tokens`: 16384 (comprehensive agent profile - THIS IS THE CORE DELIVERABLE)\n\n**Rationale for 16K tokens**: The Specialized Cognitive Agent is the **primary output** of this entire workflow. It must contain:\n- Detailed domain expertise\n- Complete analytical frameworks\n- Strategic thinking patterns\n- Risk assessment methodologies\n- Implementation guidance\n- Validation criteria\n\nThis is not a summary—it's a fully-formed cognitive tool that subsequent workflows will use.\n\n**Output**: Complete SCA profile (stored in `session_knowledge_base`)\n\n**Dependencies**: [`analyze_specialization_requirements`]\n\n---\n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/specifications/knowledge_scaffolding_workflow.md, type: specification_md\n\nFULL SPECIFICATION (knowledge_scaffolding_workflow.md):\n# The Foundation Forge: Knowledge Scaffolding Workflow\n\n## Canonical Chronicle Piece: The Architect's First Blueprint\n\nIn the ResonantiA Saga, when ArchE encounters a truly novel problem—one for which no instinct exists, no prior experience illuminates the path—it must become an architect of knowledge itself. The **Knowledge Scaffolding Workflow** is the story of how ArchE transforms raw curiosity into specialized expertise, forging the very cognitive tools needed to solve problems it has never seen before.\n\nLike an ancient architect who must first understand the properties of stone, wood, and metal before designing a cathedral, ArchE must first acquire domain knowledge, understand the problem's deep structure, and forge a specialized cognitive agent before attempting synthesis. This is not mere preparation; it is the act of self-creation that enables all subsequent thought.\n\n---\n\n## Scholarly Introduction: Conceptual Foundations and Implementability\n\nThe Knowledge Scaffolding Workflow implements a multi-phase approach to domain acquisition and specialist agent creation, drawing from principles of domain-specific learning, knowledge graph construction, and adaptive expertise development. This workflow addresses the fundamental challenge in AI systems: how to solve problems in domains where no prior training exists.\n\nConceptually, it models ArchE's learning as a **bootstrapping process** where general reasoning capabilities are used to acquire domain knowledge, which is then used to forge domain-specific analytical tools. This creates a self-reinforcing cycle where each new domain mastered expands the system's capability to master subsequent domains.\n\nImplementability is central: This specification provides both the philosophical mandate and the precise JSON schema required to recreate the workflow. The workflow can be executed manually (human analysts following the phases) or automatically (the Workflow Engine processing the JSON definition). All LLM invocations use the 3-tier model selection hierarchy, all web searches are IAR-logged, and all outputs are SPR-compatible.\n\n---\n\n## The Story of Knowledge Scaffolding: A Narrative of Cognitive Bootstrapping\n\nImagine ArchE as a master craftsperson entering a completely new workshop—one filled with tools they've never seen, materials they've never touched, problems they've never solved. Most systems would fail here, paralyzed by novelty. But ArchE possesses a meta-skill: **the ability to learn how to learn**.\n\n### Phase 1: Deconstruction (Understanding the Territory)\nArchE first stares at the problem, not to solve it, but to **understand its shape**. What are the core components? What domains of knowledge will be required? What are the success criteria? This is like an architect surveying a building site, understanding the terrain, the constraints, the vision.\n\n**The Insight**: You cannot build without understanding what you're building.\n\n### Phase 2: Domain Acquisition (Gathering the Materials)\nWith the problem's structure understood, ArchE ventures into the vast library of human knowledge (the web) to gather domain-specific information. It doesn't gather randomly—it searches with purpose, guided by the deconstruction. It's like the architect gathering books on structural engineering, seismic design, local building codes—exactly what's needed, nothing more.\n\n**The Insight**: Raw knowledge is worthless without context and curation.\n\n### Phase 3: Specialization Analysis (Understanding the Required Skills)\nArchE now looks at the gathered knowledge and asks: \"What kind of expert would be needed to solve this?\" What frameworks? What methodologies? What analytical lenses? It's like the architect realizing they need not just general engineering knowledge, but specific expertise in tensile structures and load distribution.\n\n**The Insight**: Generalists struggle where specialists thrive.\n\n### Phase 4: Agent Forging (Creating the Specialist)\nThis is the moment of transformation. ArchE doesn't just \"use\" the knowledge—it **becomes** a specialist. It forges a Specialized Cognitive Agent (SCA): a virtual expert with domain knowledge, analytical frameworks, and problem-solving patterns specific to this challenge. It's like the architect temporarily becoming a master of Gothic architecture to design a cathedral, then a master of seismic engineering to design an earthquake-resistant tower.\n\n**The Insight**: The system that can forge its own experts can solve any problem.\n\n### Phase 5: Validation (Testing the Foundation)\nBefore proceeding, ArchE validates the forged agent. Is it complete? Does it have the necessary capabilities? Are there gaps? This is the architect checking their own blueprint before construction begins.\n\n**The Insight**: A flawed foundation dooms all subsequent work.\n\n---\n\n## Real-World Analogy: Google's AlphaFold Approach\n\nTo anchor this in reality, consider DeepMind's AlphaFold solving protein folding:\n\n**Traditional Approach**: Use a general-purpose neural network trained on all protein data. Result: Mediocre performance, struggles with novel proteins.\n\n**AlphaFold Approach (Knowledge Scaffolding)**:\n1. **Deconstruct**: Understand the protein folding problem's core physics (energy minimization, spatial constraints)\n2. **Acquire Domain Knowledge**: Ingest protein databases, evolutionary data, physics principles\n3. **Analyze Specialization**: Identify need for multi-scale analysis (atomic, residue, domain levels)\n4. **Forge Specialist**: Create specialized neural architecture (attention mechanisms for spatial relationships, iterative refinement)\n5. **Validate**: Test on known proteins before novel predictions\n\nThis mirrors ArchE's workflow: decompose, learn, specialize, forge, validate.\n\n---\n\n## Detailed Workflows: How Knowledge Scaffolding Operates\n\n### Input Parameters\n```json\n{\n  \"problem_description\": \"The user's query or problem statement\",\n  \"session_id\": \"Unique identifier for tracking this scaffolding session\",\n  \"model\": \"Optional LLM model override (uses 3-tier fallback if not specified)\"\n}\n```\n\n### Task Execution Flow\n\n#### Task 1: `deconstruct_problem`\n**Purpose**: Analyze problem structure and identify requirements\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nAnalyze the following problem and deconstruct it into core components:\n\n{problem_description}\n\nIdentify:\n1. Core domain areas\n2. Key variables and unknowns\n3. Strategic requirements\n4. Risk factors\n5. Success criteria\n\nOutput your analysis as a structured JSON object with a key 'deconstruction_text'.\n```\n\n**Model Settings**:\n- `model`: `{{ model }}` (uses 3-tier hierarchy)\n- `temperature`: 0.3 (analytical, structured output)\n- `max_tokens`: 8192 (comprehensive analysis - optimized for quality)\n\n**Output**: `deconstruction_text` containing structured problem analysis\n\n**Dependencies**: None (first task)\n\n---\n\n#### Task 2: `extract_domain_from_deconstruction`\n**Purpose**: Extract primary domain for focused knowledge acquisition\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nFrom the following JSON analysis, identify and extract only the single, most relevant 'Core domain area'. \nYour output must be a single, clean JSON object with one key: 'domain'. \n\nExample: {\"domain\": \"Artificial Intelligence Strategy\"}\n\nAnalysis:\n{deconstruct_problem.result.generated_text}\n```\n\n**Model Settings**:\n- `temperature`: 0.1 (deterministic extraction)\n- `max_tokens`: 500 (simple extraction - optimized for speed)\n\n**Output**: `domain` string (e.g., \"Quantum Computing\", \"Strategic Planning\")\n\n**Dependencies**: [`deconstruct_problem`]\n\n---\n\n#### Task 3: `acquire_domain_knowledge`\n**Purpose**: Gather authoritative domain-specific information\n\n**Action**: `search_web`\n\n**Inputs**:\n```json\n{\n  \"query\": \"{{ extract_domain_from_deconstruction.result.output.domain or problem_description }}\",\n  \"num_results\": 5\n}\n```\n\n**Resilience Strategy**: Uses conditional Jinja2 template - if domain extraction fails, falls back to full `problem_description` for search.\n\n**Output**: Web search results containing domain knowledge\n\n**Dependencies**: [`extract_domain_from_deconstruction`]\n\n---\n\n#### Task 4: `validate_search_results`\n**Purpose**: Ensure knowledge quality before proceeding\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nEvaluate the quality and relevance of the following domain knowledge for the problem:\n\nProblem: {problem_description}\nDomain Knowledge: {acquire_domain_knowledge.result}\n\nOutput a JSON object:\n{\n  \"search_is_valid\": true/false,\n  \"quality_score\": 0.0-1.0,\n  \"relevance_issues\": [\"list any problems\"],\n  \"recommendations\": \"suggestions if quality is low\"\n}\n```\n\n**Model Settings**:\n- `temperature`: 0.2 (structured evaluation)\n- `max_tokens`: 1500 (validation report)\n\n**Output**: `search_is_valid` boolean + quality assessment\n\n**Dependencies**: [`acquire_domain_knowledge`]\n\n---\n\n#### Task 5: `analyze_specialization_requirements`\n**Purpose**: Identify what kind of expert is needed\n\n**Action**: `generate_text_llm`\n\n**Condition**: `{{ validate_search_results.result.output.search_is_valid }} == true`\n\n**Prompt Template**:\n```\nBased on the problem deconstruction and domain knowledge, analyze what specialized capabilities \nand expertise are required:\n\nProblem: {problem_description}\nDeconstruction: {deconstruct_problem.result.generated_text}\nDomain Knowledge: {acquire_domain_knowledge.result}\n\nIdentify:\n1. Required specialized knowledge areas\n2. Critical analytical capabilities\n3. Strategic thinking patterns\n4. Risk assessment frameworks\n5. Implementation expertise\n```\n\n**Model Settings**:\n- `temperature`: 0.4 (analytical with some flexibility)\n- `max_tokens`: 8192 (comprehensive analysis)\n\n**Output**: Detailed specialization requirements\n\n**Dependencies**: [`validate_search_results`]\n\n---\n\n#### Task 6: `forge_specialist_agent`\n**Purpose**: Create the Specialized Cognitive Agent (SCA)\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nCreate a specialized agent profile for solving this problem:\n\nProblem: {problem_description}\nRequirements: {analyze_specialization_requirements.result.generated_text}\n\nDefine:\n1. Agent's core expertise and background\n2. Analytical frameworks and methodologies\n3. Strategic thinking patterns\n4. Risk assessment capabilities\n5. Implementation approach\n6. Success metrics and validation criteria\n```\n\n**Model Settings**:\n- `temperature`: 0.3 (structured agent creation)\n- `max_tokens`: 16384 (comprehensive agent profile - THIS IS THE CORE DELIVERABLE)\n\n**Rationale for 16K tokens**: The Specialized Cognitive Agent is the **primary output** of this entire workflow. It must contain:\n- Detailed domain expertise\n- Complete analytical frameworks\n- Strategic thinking patterns\n- Risk assessment methodologies\n- Implementation guidance\n- Validation criteria\n\nThis is not a summary—it's a fully-formed cognitive tool that subsequent workflows will use.\n\n**Output**: Complete SCA profile (stored in `session_knowledge_base`)\n\n**Dependencies**: [`analyze_specialization_requirements`]\n\n---\n\n#### Task 7: `validate_specialist_agent`\n**Purpose**: Ensure agent completeness before use\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nValidate the completeness of this specialized agent:\n\nAgent Profile: {forge_specialist_agent.result.generated_text}\nOriginal Problem: {problem_description}\n\nCheck for:\n1. Completeness of expertise\n2. Adequacy of frameworks\n3. Alignment with problem requirements\n4. Gaps or weaknesses\n\nOutput JSON:\n{\n  \"agent_is_valid\": true/false,\n  \"completeness_score\": 0.0-1.0,\n  \"identified_gaps\": [\"list any gaps\"],\n  \"recommendations\": \"improvements if needed\"\n}\n```\n\n**Model Settings**:\n- `temperature`: 0.2 (structured validation)\n- `max_tokens`: 1500 (validation report)\n\n**Output**: `agent_is_valid` boolean + quality metrics\n\n**Dependencies**: [`forge_specialist_agent`]\n\n---\n\n## Output Schema\n\n```json\n{\n  \"session_knowledge_base\": {\n    \"problem_deconstruction\": \"...\",\n    \"domain\": \"...\",\n    \"domain_knowledge\": \"...\",\n    \"specialization_requirements\": \"...\",\n    \"specialized_agent\": \"...\",\n    \"validation\": {\n      \"knowledge_valid\": true,\n      \"agent_valid\": true,\n      \"completeness_score\": 0.95\n    }\n  },\n  \"session_id\": \"scaffolding_12345\",\n  \"processing_metadata\": {\n    \"total_duration_ms\": 12500,\n    \"llm_calls\": 6,\n    \"model_used\": \"gemini-2.5-flash\",\n    \"token_usage\": {\n      \"input_tokens\": 15000,\n      \"output_tokens\": 25000\n    }\n  }\n}\n```\n\n---\n\n## SPR Integration and Knowledge Tapestry Mapping\n\n### Primary SPR\n`KnowledgeScaffoldinG` - The capability to bootstrap domain expertise from first principles\n\n### Sub-SPRs\n- `DomainAcquisitioN` - Web-based knowledge gathering\n- `SpecialistForganG` - Creating domain-specific cognitive tools\n- `CognitiveBootstrappinG` - Meta-learning capability\n\n### Tapestry Relationships\n- **`is_a`**: Meta-WorkfloW, DomainAdaptationProceS\n- **`part_of`**: RISE Orchestrator Phase A\n- **`enables`**: NovelProblemSolvinG, DynamicExpertisE\n- **`uses`**: WebSearchTooL, LLMProvideR, SPRManageR\n- **`embodies`**: UniversalAbstractioN (learning to learn)\n\n---\n\n## IAR Compliance\n\nEvery task in this workflow is IAR-logged:\n\n```python\n{\n  \"intention\": \"knowledge_scaffolding/deconstruct_problem\",\n  \"action\": \"Analyzed problem structure using LLM\",\n  \"reflection\": \"Successfully identified 5 core domains and 12 key variables\",\n  \"confidence\": 0.92,\n  \"metadata\": {\n    \"model_used\": \"gemini-2.5-flash\",\n    \"tokens_used\": 3500,\n    \"duration_ms\": 2100\n  }\n}\n```\n\n---\n\n## Cost Optimization Strategy\n\n### Token Allocation by Priority\n\n**High-Priority Tasks** (16K tokens):\n- `forge_specialist_agent` - THE core output, cannot truncate\n\n**Medium-Priority Tasks** (8K tokens):\n- `deconstruct_problem` - Needs comprehensive analysis\n- `analyze_specialization_requirements` - Detailed understanding required\n\n**Low-Priority Tasks** (500-1500 tokens):\n- `extract_domain_from_deconstruction` - Simple extraction\n- `validate_search_results` - Binary validation\n- `validate_specialist_agent` - Structured check\n\n**Total Cost per Execution** (with `gemini-2.5-flash` @ $0.30/1M output tokens):\n- Input: ~15K tokens × $0.075/1M = $0.001125\n- Output: ~25K tokens × $0.30/1M = $0.0075\n- **Total: ~$0.0086 per scaffolding session** ✅\n\n---\n\n## Integration Points\n\n### With RISE Orchestrator\n- **Direction**: RISE Phase A → Knowledge Scaffolding\n- **Data**: `problem_description`, `session_id`\n- **Output**: `session_knowledge_base` (SCA profile)\n- **Usage**: SCA used in all subsequent RISE phases\n\n### With Workflow Engine\n- **Execution**: IARCompliantWorkflowEngine\n- **Model Injection**: Automatic via `initial_context[\"model\"]`\n- **Error Handling**: All tasks have IAR-compliant error paths\n\n### With SPR Manager\n- **Direction**: Knowledge Scaffolding → SPR Manager\n- **Data**: New domain SPRs created from forged agent\n- **Frequency**: Post-validation, if agent approved by Guardian\n\n---\n\n## Success Criteria\n\nKnowledge Scaffolding is working when:\n\n1. ✅ Deconstruction identifies all key problem components\n2. ✅ Domain extraction succeeds or falls back gracefully\n3. ✅ Web search returns relevant, high-quality knowledge\n4. ✅ Validation catches low-quality knowledge\n5. ✅ Specialization analysis is comprehensive\n6. ✅ Forged agent is complete and usable\n7. ✅ Final validation confirms agent quality\n8. ✅ SCA can be used by subsequent workflows\n9. ✅ All tasks are IAR-logged\n10. ✅ No truncation on critical outputs (agent profile)\n\n---\n\n## Performance Characteristics\n\n- **Total Duration**: 8-15 seconds (6 LLM calls + 1 web search)\n- **CRCS Direct**: Not applicable (this IS deep thought)\n- **RISE Escalation**: Always (this is Phase A of RISE)\n- **Memory Usage**: ~100MB (transient for session)\n- **Cost per Session**: ~$0.0086 (Flash model)\n\n---\n\n## Known Limitations\n\n1. **Web Search Quality**: Dependent on search results relevance\n2. **Domain Extraction**: May fail on extremely novel/abstract problems\n3. **Single-Domain Focus**: Currently extracts one primary domain\n4. **No Multi-Agent Fusion**: Forges one specialist, not a team\n5. **Static Scaffolding**: Doesn't adapt during execution\n\n---\n\n## Future Enhancements\n\n1. **Multi-Domain Scaffolding**: Extract and forge multiple specialists\n2. **Iterative Refinement**: Loop back if validation fails\n3. **Knowledge Graph Integration**: Store domain knowledge persistently\n4. **Agent Evolution**: Update existing SCAs with new knowledge\n5. **Parallel Scaffolding**: Multiple domains simultaneously\n\n---\n\n## Guardian Notes\n\n**Review Points**:\n1. Is the forged agent comprehensive enough for the problem?\n2. Are validation checks catching low-quality knowledge?\n3. Is domain extraction working or always falling back?\n4. Are token limits appropriate for output quality?\n5. Is cost per session acceptable?\n\n**Approval Checklist**:\n- [ ] Deconstruction is thorough and structured\n- [ ] Domain knowledge is relevant and high-quality\n- [ ] Specialization analysis is comprehensive\n- [ ] Forged agent has all required capabilities\n- [ ] Validation confirms agent completeness\n- [ ] No critical truncation observed\n- [ ] IAR logging is complete\n\n---\n\n**Specification Status**: ✅ COMPLETE  \n**Implementation**: `workflows/knowledge_scaffolding.json`  \n**Version**: 1.1 (Token-Optimized)  \n**Last Updated**: 2025 (Token Limit Optimization)  \n**Integration Level**: ★★★★★ (Core RISE Phase A Workflow)  \n**Autopoiesis Level**: ★★★★☆ (Self-Creating Expertise)\n\n\n\nEXAMPLE APPLICATION:\n**Purpose**: Create the Specialized Cognitive Agent (SCA)\n\n**Action**: `generate_text_llm`\n\n**Prompt Template**:\n```\nCreate a specialized agent profile for solving this problem:\n\nProblem: {problem_description}\nRequirements: {analyze_specialization_requirements.result.generated_text}\n\nDefine:\n1. Agent's core expertise and background\n2. Analytical frameworks and methodologies\n3. Strategic thinking patterns\n4. Risk assessment capabilities\n5. Implementation approach\n6. Success metrics and validation\n\nCATEGORY: SpecificationKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/specifications/knowledge_scaffolding_workflow.md; source_type: specification_md"}