{"content": "TERM: SPR Manager\n\nDEFINITION:\nThe knowledge management system responsible for managing Sparse Priming Representations (SPRs) in the Knowledge Tapestry. It handles SPR creation, updates, validation, and retrieval operations.\n\n[From agi.txt]: SPR: 1.640, \"Workflow Management\"\n\n[From Codebase]: Use SPR relationships to map codebase components and their interdependencies.\n\n[From Codebase]: Class: SPRManager\n\nManages Synergistic Protocol Resonance (SPR) definitions from a JSON file.\n\nMethods: __init__, load_sprs, _compile_spr_pattern, scan_and_prime, detect_sprs_with_confidence, _calculate_spr_activation, _calculate_spr_confidence, _decompose_camelcase, _get_semantic_variations, _calculate_context_relevance\n\nBLUEPRINT DETAILS:\nSPR management implementation in Three_PointO_ArchE/spr_manager.py with SPRManager class providing load_sprs(), get_spr_by_id(), search_sprs() methods for comprehensive knowledge management.\n\nFULL IMPLEMENTATION CODE (spr_manager.py):\n```python\nimport json\nimport logging\nimport re\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Optional, Set\nfrom .thought_trail import log_to_thought_trail\n\nlogger = logging.getLogger(__name__)\n\n# Lazy import for Zepto compression (optional dependency)\n_zepto_processor = None\n\ndef _get_zepto_processor():\n    \"\"\"Lazy initialization of Zepto processor.\"\"\"\n    global _zepto_processor\n    if _zepto_processor is None:\n        try:\n            from .zepto_spr_processor import ZeptoSPRProcessorAdapter\n            _zepto_processor = ZeptoSPRProcessorAdapter()\n            logger.info(\"Zepto SPR processor initialized for automatic compression\")\n        except Exception as e:\n            logger.warning(f\"Zepto SPR processor not available: {e}. Zepto compression will be skipped.\")\n            _zepto_processor = False  # Mark as unavailable\n    return _zepto_processor if _zepto_processor is not False else None\n\nclass SPRManager:\n    \"\"\"Manages Synergistic Protocol Resonance (SPR) definitions from a JSON file.\"\"\"\n\n    def __init__(self, spr_filepath: str):\n        \"\"\"\n        Initializes the SPRManager and loads the definitions.\n\n        Args:\n            spr_filepath: The path to the JSON file containing SPR definitions.\n        \"\"\"\n        if not spr_filepath:\n            raise ValueError(\"SPRManager requires a valid file path.\")\n        \n        self.filepath = Path(spr_filepath).resolve()\n        self.sprs: Dict[str, Dict[str, Any]] = {}\n        self.spr_pattern: Optional[re.Pattern] = None\n        self.load_sprs()\n\n    @log_to_thought_trail\n    def load_sprs(self):\n        \"\"\"Loads or reloads the SPR definitions from the JSON file.\"\"\"\n        try:\n            with open(self.filepath, 'r', encoding='utf-8') as f:\n                spr_data = json.load(f)\n            \n            # Handle both dict and list formats\n            if isinstance(spr_data, dict):\n                # If it's a dictionary with spr_id keys, use them directly\n                self.sprs = spr_data\n                logger.info(f\"Successfully loaded {len(self.sprs)} SPR definitions from {self.filepath} (dict format)\")\n            elif isinstance(spr_data, list):\n                # If it's a list of objects, extract spr_id keys\n                self.sprs = {spr['spr_id']: spr for spr in spr_data if isinstance(spr, dict) and 'spr_id' in spr}\n                logger.info(f\"Successfully loaded {len(self.sprs)} SPR definitions from {self.filepath} (list format)\")\n            else:\n                logger.error(f\"SPR data format is unrecognized in {self.filepath}\")\n                self.sprs = {}\n                \n        except FileNotFoundError:\n            logger.warning(f\"SPR file not found at {self.filepath}. Initializing with empty definitions.\")\n            self.sprs = {}\n        except json.JSONDecodeError:\n            logger.error(f\"Failed to decode JSON from {self.filepath}. Check file for syntax errors.\")\n            self.sprs = {}\n        except (TypeError, KeyError) as e:\n            logger.error(f\"SPR data format is invalid in {self.filepath}: {e}\")\n            self.sprs = {}\n        \n        self._compile_spr_pattern()\n\n    def _compile_spr_pattern(self):\n        \"\"\"\n        Compiles a regex pattern to efficiently find all registered SPR keys in a text.\n        This is the 'musician learning the music'.\n        \"\"\"\n        if not self.sprs:\n            self.spr_pattern = None\n            return\n        # The keys are the spr_id's themselves\n        spr_keys = [re.escape(key) for key in self.sprs.keys()]\n        # Create a single regex pattern to find any of the keys as whole words\n        pattern_str = r'\\b(' + '|'.join(spr_keys) + r')\\b'\n        self.spr_pattern = re.compile(pattern_str)\n        logger.info(f\"Compiled SPR pattern for {len(spr_keys)} keys.\")\n\n    @log_to_thought_trail\n    def scan_and_prime(self, text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Scans a given text for all occurrences of registered SPR keys and returns\n        the full definitions for each unique SPR found. This is 'striking the bells'.\n        \"\"\"\n        if not self.spr_pattern or not isinstance(text, str):\n            return []\n        \n        found_sprs: Set[str] = set(self.spr_pattern.findall(text))\n        \n        if found_sprs:\n            logger.debug(f\"Primed {len(found_sprs)} unique SPRs: {', '.join(sorted(list(found_sprs)))}\")\n        \n        return [self.sprs[key] for key in sorted(list(found_sprs)) if key in self.sprs]\n    \n    @log_to_thought_trail\n    def detect_sprs_with_confidence(self, text: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Enhanced SPR detection with fuzzy matching, confidence scoring, and activation levels.\n        Incorporates frontend sophistication into backend processing.\n        \"\"\"\n        if not isinstance(text, str) or not text.strip():\n            return []\n        \n        detected_sprs = []\n        lower_text = text.lower()\n        \n        for spr_id, spr_data in self.sprs.items():\n            activation_level = self._calculate_spr_activation(lower_text, spr_id)\n            \n            if activation_level > 0.3:  # Threshold for detection\n                confidence_score = self._calculate_spr_confidence(lower_text, spr_id, activation_level)\n                \n                detected_sprs.append({\n                    'spr_id': spr_id,\n                    'spr_data': spr_data,\n                    'activation_level': activation_level,\n                    'confidence_score': confidence_score,\n                    'guardian_point': spr_id,\n                    'knowledge_network': {\n                        'resonance_frequency': self._calculate_resonance_frequency(spr_id),\n                        'activation_history': self._get_activation_history(spr_id),\n                        'related_sprs': self._get_related_sprs(spr_id)\n                    }\n                })\n        \n        # Sort by confidence score (highest first), then by activation level as tiebreaker\n        detected_sprs.sort(key=lambda x: (x['confidence_score'], x['activation_level']), reverse=True)\n        \n        return detected_sprs\n    \n    def _calculate_spr_activation(self, text: str, spr_id: str) -> float:\n        \"\"\"Calculate SPR activation level using fuzzy matching techniques.\"\"\"\n        spr_data = self.sprs.get(spr_id, {})\n        spr_term = spr_data.get('term', '').lower()\n        spr_definition = spr_data.get('definition', '').lower()\n        lower_spr = spr_id.lower()\n        \n        # Common words that should not match very short SPRs (1-2 chars)\n        common_words = {'in', 'on', 'at', 'to', 'of', 'for', 'is', 'it', 'as', 'an', 'or', 'be', 'we', 'if', 'my', 'up', 'so', 'no', 'go', 'do', 'by', 'me', 'he', 'us', 'am', 'id'}\n        \n        # Penalty for very short SPRs matching common words\n        if len(spr_id) <= 2 and spr_id.upper() in common_words:\n            # Only match if it's a whole word with word boundaries\n            import re\n            pattern = r'\\b' + re.escape(spr_id.lower()) + r'\\b'\n            if not re.search(pattern, text):\n                return 0.0  # Reject substring matches for common short SPRs\n        \n        # Check for exact SPR ID matches (highest priority)\n        if lower_spr in text:\n            return 0.95\n        \n        # Check SPR term and definition for semantic relevance (high priority)\n        term_score = 0.0\n        if spr_term:\n            # Exact term match\n            if spr_term in text:\n                term_score = 0.9\n            else:\n                # Check if key words from term are in text\n                term_words = spr_term.split()\n                matching_words = sum(1 for word in term_words if len(word) > 2 and word in text)\n                if matching_words > 0:\n                    term_score = min(0.8, matching_words * 0.3)\n        \n        definition_score = 0.0\n        if spr_definition:\n            # Check if key words from definition are in text\n            def_words = spr_definition.split()\n            matching_words = sum(1 for word in def_words if len(word) > 3 and word in text)\n            if matching_words > 0:\n                definition_score = min(0.6, matching_words * 0.15)\n        \n        # Check for partial matches using CamelCase decomposition\n        words = self._decompose_camelcase(spr_id)\n        camelcase_score = 0.0\n        for word in words:\n            if len(word) > 2 and word.lower() in text:\n                camelcase_score += 0.15\n        \n        # Check for semantic variations\n        variations = self._get_semantic_variations(spr_id)\n        variation_score = 0.0\n        for variation in variations:\n            if variation.lower() in text:\n                variation_score += 0.2\n        \n        # Combine scores with priority: term > definition > camelcase > variations\n        match_score = max(term_score, definition_score * 0.8, camelcase_score, variation_score)\n        \n        return min(0.95, match_score)\n    \n    def _calculate_spr_confidence(self, text: str, spr_id: str, activation_level: float) -> float:\n        \"\"\"Calculate confidence score using weighted factors.\"\"\"\n        context_relevance = self._calculate_context_relevance(text, spr_id)\n        semantic_clarity = self._calculate_semantic_clarity(text, spr_id)\n        \n        return (activation_level * 0.5) + (context_relevance * 0.3) + (semantic_clarity * 0.2)\n    \n    def _decompose_camelcase(self, text: str) -> List[str]:\n        \"\"\"Decompose CamelCase text into individual words.\"\"\"\n        import re\n        return re.findall(r'[A-Z][a-z]*|[a-z]+', text)\n    \n    def _get_semantic_variations(self, spr_id: str) -> List[str]:\n        \"\"\"Get semantic variations for SPR detection.\"\"\"\n        spr_data = self.sprs.get(spr_id, {})\n        spr_term = spr_data.get('term', '').lower()\n        \n        # Build variations from SPR term if available\n        variations = []\n        if spr_term:\n            # Add the term itself as a variation\n            variations.append(spr_term)\n            # Add key phrases from term (2-3 word combinations)\n            term_words = spr_term.split()\n            if len(term_words) >= 2:\n                # Add bigrams\n                for i in range(len(term_words) - 1):\n                    bigram = f\"{term_words[i]} {term_words[i+1]}\"\n                    if len(bigram) > 5:  # Only meaningful bigrams\n                        variations.append(bigram)\n        \n        # Hardcoded variations for known SPRs\n        variations_map = {\n            'ExecutableSpecificationPrinciple': ['specification principle', 'executable principle', 'spec principle'],\n            'AutopoieticSystemGenesis': ['autopoietic genesis', 'system genesis', 'self-creation'],\n            'IntegratedActionReflection': ['action reflection', 'integrated reflection', 'reflection principle', 'IAR'],\n            'SparsePrimingRepresentations': ['sparse priming', 'priming representations', 'SPR'],\n            'VisualCognitiveDebugger': ['visual debugger', 'cognitive debugger', 'VCD'],\n            'ResonantInsightStrategyEngine': ['resonant insight', 'strategy engine', 'RISE'],\n            'SynergisticIntentResonanceCycle': ['synergistic intent', 'resonance cycle', 'SIRC'],\n            'CognitiveResonanceCycle': ['cognitive resonance', 'resonance cycle', 'CRC'],\n            'CoreworkflowenginE': ['workflow engine', 'core workflow', 'workflow system'],\n            'IarcompliantworkflowenginE': ['IAR workflow', 'workflow engine', 'IAR compliant'],\n            'WorkflowchainingenginE': ['workflow engine', 'workflow chaining', 'chaining engine']\n        }\n        \n        # Merge hardcoded variations with term-based variations\n        hardcoded = variations_map.get(spr_id, [])\n        variations.extend(hardcoded)\n        \n        # Remove duplicates while preserving order\n        seen = set()\n        unique_variations = []\n        for v in variations:\n            v_lower = v.lower()\n            if v_lower not in seen:\n                seen.add(v_lower)\n                unique_variations.append(v)\n        \n        return unique_variations\n    \n    def _calculate_context_relevance(self, text: str, spr_id: str) -> float:\n        \"\"\"Calculate how well the SPR fits the current context.\"\"\"\n        spr_data = self.sprs.get(spr_id, {})\n        spr_term = spr_data.get('term', '').lower()\n        spr_definition = spr_data.get('definition', '').lower()\n        \n        if not spr_term and not spr_definition:\n            return 0.5  # Low relevance if no term/definition\n        \n        # Extract key query words (longer than 3 chars, not common stop words)\n        stop_words = {'what', 'is', 'are', 'the', 'a', 'an', 'this', 'that', 'these', 'those', 'how', 'does', 'do', 'tell', 'me', 'about', 'explain', 'define'}\n        query_words = [w for w in text.split() if len(w) > 3 and w.lower() not in stop_words]\n        \n        if not query_words:\n            return 0.6  # Base relevance if no meaningful query words\n        \n        # Check how many query words appear in SPR term/definition\n        term_matches = sum(1 for word in query_words if word.lower() in spr_term)\n        def_matches = sum(1 for word in query_words if word.lower() in spr_definition)\n        \n        # Calculate relevance score\n        total_matches = term_matches + (def_matches * 0.5)  # Term matches weighted higher\n        max_possible = len(query_words) * 1.5  # Max possible matches\n        \n        if max_possible > 0:\n            relevance = min(1.0, total_matches / max_possible)\n        else:\n            relevance = 0.6\n        \n        return relevance\n    \n    def _calculate_semantic_clarity(self, text: str, spr_id: str) -> float:\n        \"\"\"Calculate semantic clarity of the SPR in context.\"\"\"\n        # This would analyze semantic clarity - for now return a base score\n        return 0.8\n    \n    def _calculate_resonance_frequency(self, spr_id: str) -> float:\n        \"\"\"Calculate resonance frequency for the SPR.\"\"\"\n        # This would come from historical data - for now return a simulated value\n        import random\n        return random.uniform(0.2, 1.0)\n    \n    def _get_activation_history(self, spr_id: str) -> List[str]:\n        \"\"\"Get activation history for the SPR.\"\"\"\n        # This would come from historical data - for now return simulated history\n        import random\n        count = random.randint(1, 10)\n        return [f\"{spr_id} activated {count} times in recent sessions\"]\n    \n    def _get_related_sprs(self, spr_id: str) -> List[str]:\n        \"\"\"Get related SPRs for the given SPR.\"\"\"\n        # This would come from relationship data - for now return related SPRs\n        all_sprs = list(self.sprs.keys())\n        return [spr for spr in all_sprs if spr != spr_id][:3]\n\n    def _save_sprs(self) -> bool:\n        \"\"\"Saves the current state of SPR definitions back to the JSON file.\"\"\"\n        try:\n            with open(self.filepath, 'w', encoding='utf-8') as f:\n                # The file is a list of the dictionary values\n                json.dump(list(self.sprs.values()), f, indent=2)\n            logger.info(f\"Successfully saved {len(self.sprs)} SPRs to {self.filepath}\")\n            return True\n        except Exception as e:\n            logger.error(f\"Failed to save SPR file to {self.filepath}: {e}\", exc_info=True)\n            return False\n\n    @log_to_thought_trail\n    def add_spr(self, spr_definition: Dict[str, Any], save_to_file: bool = True, overwrite_if_exists: bool = True) -> bool:\n        \"\"\"\n        Adds a new SPR to the manager and optionally saves the updated ledger to file.\n        This is 'forging a new bell'.\n        \n        Automatically compresses to Zepto SPR if zepto_spr is missing or empty.\n        \n        Args:\n            spr_definition: SPR definition dictionary\n            save_to_file: Whether to save to file immediately\n            overwrite_if_exists: Whether to overwrite if SPR already exists\n            \n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        spr_id = spr_definition.get(\"spr_id\")\n        if not spr_id:\n            logger.error(\"Cannot add SPR: 'spr_id' is a required field.\")\n            return False\n            \n        if spr_id in self.sprs:\n            if not overwrite_if_exists:\n                logger.warning(f\"SPR with id '{spr_id}' already exists and overwrite_if_exists=False. Skipping.\")\n                return False\n            logger.warning(f\"SPR with id '{spr_id}' already exists. Overwriting.\")\n            \n        # AUTOMATIC ZEPTO COMPRESSION: If zepto_spr is missing or empty, compress automatically\n        zepto_spr = spr_definition.get(\"zepto_spr\", \"\")\n        if not zepto_spr or zepto_spr.strip() == \"\" or zepto_spr == \"Ξ\":\n            # Build narrative from definition\n            definition = spr_definition.get(\"definition\", \"\")\n            term = spr_definition.get(\"term\", spr_id)\n            \n            # Create narrative for compression\n            narrative_parts = []\n            if term:\n                narrative_parts.append(term)\n            if definition:\n                narrative_parts.append(definition)\n            \n            narrative = \" \".join(narrative_parts).strip()\n            \n            if narrative and len(narrative) > 10:\n                # Compress to Zepto\n                zepto_processor = _get_zepto_processor()\n                if zepto_processor:\n                    try:\n                        result = zepto_processor.compress_to_zepto(\n                            narrative=narrative,\n                            target_stage=\"Zepto\"\n                        )\n                        \n                        if result and not result.error and result.zepto_spr:\n                            spr_definition[\"zepto_spr\"] = result.zepto_spr\n                            \n                            # Update symbol_codex if new entries were created\n                            if result.new_codex_entries:\n                                existing_codex = spr_definition.get(\"symbol_codex\", {})\n                                # Convert SymbolCodexEntry objects to dicts\n                                from dataclasses import asdict\n                                for symbol, entry in result.new_codex_entries.items():\n                                    if hasattr(entry, '__dict__'):\n                                        existing_codex[symbol] = asdict(entry)\n                                    else:\n                                        existing_codex[symbol] = entry\n                                spr_definition[\"symbol_codex\"] = existing_codex\n                            \n                            logger.info(f\"Auto-compressed SPR '{spr_id}' to Zepto: {len(narrative)} → {len(result.zepto_spr)} chars ({result.compression_ratio:.1f}:1)\")\n                        else:\n                            logger.warning(f\"Zepto compression failed for SPR '{spr_id}': {result.error if result else 'Unknown error'}\")\n                            spr_definition[\"zepto_spr\"] = \"Ξ\"  # Default unknown symbol\n                    except Exception as e:\n                        logger.warning(f\"Exception during Zepto compression for SPR '{spr_id}': {e}\")\n                        spr_definition[\"zepto_spr\"] = \"Ξ\"  # Default unknown symbol\n                else:\n                    logger.debug(f\"Zepto processor not available, skipping compression for SPR '{spr_id}'\")\n                    spr_definition[\"zepto_spr\"] = \"Ξ\"  # Default unknown symbol\n            else:\n                logger.debug(f\"Insufficient narrative for Zepto compression of SPR '{spr_id}'\")\n                spr_definition[\"zepto_spr\"] = \"Ξ\"  # Default unknown symbol\n        \n        self.sprs[spr_id] = spr_definition\n        logger.info(f\"Added/Updated SPR '{spr_id}' in memory.\")\n        \n        # Re-compile the pattern to include the new key\n        self._compile_spr_pattern()\n        \n        if save_to_file:\n            return self._save_sprs()\n        \n        return True\n\n    @log_to_thought_trail\n    def get_spr_by_id(self, spr_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Retrieves a single SPR definition by its ID.\n\n        Args:\n            spr_id: The ID of the SPR to retrieve.\n\n        Returns:\n            A dictionary containing the SPR definition, or None if not found.\n        \"\"\"\n        return self.sprs.get(spr_id)\n\n    @log_to_thought_trail\n    def get_all_sprs(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Retrieves all loaded SPR definitions.\n\n        Returns:\n            A list of all SPR definition dictionaries.\n        \"\"\"\n        return list(self.sprs.values())\n\n    @log_to_thought_trail\n    def search_sprs(self, query: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Searches SPR definitions for a query string in the name or description.\n\n        Args:\n            query: The string to search for.\n\n        Returns:\n            A list of matching SPR definitions.\n        \"\"\"\n        results = []\n        query_lower = query.lower()\n        for spr in self.sprs.values():\n            name = spr.get('name', '').lower()\n            description = spr.get('description', '').lower()\n            if query_lower in name or query_lower in description:\n                results.append(spr)\n        return results\n    \n    # --- Universal Zepto SPR Integration Methods ---\n    \n    @log_to_thought_trail\n    def compress_spr_to_zepto(\n        self,\n        spr_id: str,\n        target_stage: str = \"Zepto\"\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Compress an SPR definition to Zepto SPR form using universal abstraction.\n        \n        Args:\n            spr_id: The SPR ID to compress\n            target_stage: Compression stage target (default: \"Zepto\")\n            \n        Returns:\n            Dictionary with zepto_spr and metadata, or None if SPR not found\n        \"\"\"\n        try:\n            from .zepto_spr_processor import compress_to_zepto\n            \n            spr = self.get_spr_by_id(spr_id)\n            if not spr:\n                logger.warning(f\"SPR '{spr_id}' not found for Zepto compression\")\n                return None\n            \n            # Convert SPR definition to narrative form\n            narrative = self._spr_to_narrative(spr)\n            \n            # Compress using universal abstraction\n            result = compress_to_zepto(narrative, target_stage)\n            \n            if result.error:\n                logger.error(f\"Zepto compression failed for SPR '{spr_id}': {result.error}\")\n                return None\n            \n            return {\n                'spr_id': spr_id,\n                'zepto_spr': result.zepto_spr,\n                'compression_ratio': result.compression_ratio,\n                'compression_stages': result.compression_stages,\n                'new_codex_entries': result.new_codex_entries,\n                'original_length': result.original_length,\n                'zepto_length': result.zepto_length,\n                'processing_time_sec': result.processing_time_sec\n            }\n            \n        except ImportError as e:\n            logger.warning(f\"Zepto SPR processor not available: {e}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error compressing SPR '{spr_id}' to Zepto: {e}\", exc_info=True)\n            return None\n    \n    @log_to_thought_trail\n    def decompress_zepto_to_spr(\n        self,\n        zepto_spr: str,\n        codex: Optional[Dict[str, Any]] = None\n    ) -> Optional[str]:\n        \"\"\"\n        Decompress a Zepto SPR back to narrative form using universal abstraction.\n        \n        Args:\n            zepto_spr: The Zepto SPR string to decompress\n            codex: Optional symbol codex (uses default if None)\n            \n        Returns:\n            Decompressed narrative string, or None on error\n        \"\"\"\n        try:\n            from .zepto_spr_processor import decompress_from_zepto\n            \n            result = decompress_from_zepto(zepto_spr, codex)\n            \n            if result.error:\n                logger.error(f\"Zepto decompression failed: {result.error}\")\n                return None\n            \n            return result.decompressed_text\n            \n        except ImportError as e:\n            logger.warning(f\"Zepto SPR processor not available: {e}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error decompressing Zepto SPR: {e}\", exc_info=True)\n            return None\n    \n    def _spr_to_narrative(self, spr: Dict[str, Any]) -> str:\n        \"\"\"\n        Convert SPR definition dictionary to narrative form for compression.\n        \n        Args:\n            spr: SPR definition dictionary\n            \n        Returns:\n            Narrative string representation\n        \"\"\"\n        parts = []\n        \n        spr_id = spr.get('spr_id', 'Unknown')\n        name = spr.get('name', spr_id)\n        description = spr.get('description', '')\n        category = spr.get('category', '')\n        relationships = spr.get('relationships', {})\n        blueprint_details = spr.get('blueprint_details', '')\n        \n        parts.append(f\"SPR ID: {spr_id}\")\n        parts.append(f\"Name: {name}\")\n        if description:\n            parts.append(f\"Description: {description}\")\n        if category:\n            parts.append(f\"Category: {category}\")\n        if relationships:\n            parts.append(f\"Relationships: {json.dumps(relationships, indent=2)}\")\n        if blueprint_details:\n            parts.append(f\"Blueprint Details: {blueprint_details}\")\n        \n        return \"\\n\".join(parts)\n    \n    @log_to_thought_trail\n    def batch_compress_sprs_to_zepto(\n        self,\n        spr_ids: Optional[List[str]] = None,\n        target_stage: str = \"Zepto\"\n    ) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Batch compress multiple SPRs to Zepto form.\n        \n        Args:\n            spr_ids: List of SPR IDs to compress (None = all SPRs)\n            target_stage: Compression stage target\n            \n        Returns:\n            Dictionary mapping spr_id to compression results\n        \"\"\"\n        if spr_ids is None:\n            spr_ids = list(self.sprs.keys())\n        \n        results = {}\n        for spr_id in spr_ids:\n            result = self.compress_spr_to_zepto(spr_id, target_stage)\n            if result:\n                results[spr_id] = result\n        \n        logger.info(f\"Batch compressed {len(results)} SPRs to Zepto form\")\n        return results\n\n```\n\nEXAMPLE APPLICATION:\nThe SPRmanageR maintains the Knowledge Tapestry, enabling rapid SPR retrieval, knowledge evolution through Insight Solidification, and cognitive key activation for complex problem-solving scenarios.\n\nCATEGORY: SystemComponent\n\nRELATIONSHIPS:\ntype: KnowledgeManager; manages: SPRs, Knowledge Tapestry, SPR Definitions; enables: SPR Creation, SPR Updates, SPR Validation; provides: Knowledge Retrieval, SPR Indexing, Knowledge Evolution; confidence: high"}