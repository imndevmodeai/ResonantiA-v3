{"content": "TERM: Class: MockLLM\n\nDEFINITION:\nClass: MockLLM\n\nMethods: generate_text\n\nBLUEPRINT DETAILS:\nExtracted from /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/strategic_workflow_planner.py, type: python_class\n\nFULL IMPLEMENTATION CODE (strategic_workflow_planner.py):\n```python\n\"\"\"\nStrategic Workflow Planner (The Mind of RISE)\n==============================================\n\nAs Above: The Principle of Isomorphism\n---------------------------------------\nThe universe repeats its patterns at every scale. The optimal path for a fleet of vehicles delivering packages is, structurally, the same problem as the optimal path for a series of cognitive actions achieving a complex goal. Both are graphs of nodes (locations/tasks) and edges (travel time/dependencies) that can be solved with the same universal principles of combinatorial optimization. This planner is the bridge between these two domains. It does not invent new logic; it recognizes the isomorphism between a complex query and a Vehicle Routing Problem and performs the translation.\n\nSo Below: The Operational Logic\n-------------------------------\nThis module provides the `StrategicWorkflowPlanner` class. Its purpose is to act as the \"mind\" for the RISE engine. It takes a high-concept, multi-step query (a \"blueprint\") and translates it into a formal optimization problem that can be solved by the existing `AdvancedTSPSolver` (which uses Google OR-Tools).\n\nThe process is as follows:\n1.  **Deconstruction:** An LLM is used to break the blueprint into abstract goals and their dependencies.\n2.  **Problem Formulation:** These goals are mapped to concrete system actions, and the dependencies are used to define constraints. Costs are estimated.\n3.  **Translation to VRP:** The entire abstract workflow is converted into a dictionary that matches the input schema of the `AdvancedTSPSolver` (the Vehicle Routing Problem format).\n4.  **Invocation:** The solver is called to find the optimal sequence of actions.\n5.  **Translation to Workflow:** The solver's output (a set of routes) is translated back into a standard, executable ArchE workflow JSON file.\n\"\"\"\n\nimport logging\nimport json\nfrom typing import Dict, Any, List\n\nfrom Three_PointO_ArchE.action_registry import main_action_registry\n\n# We will eventually import the TSP solver and LLM provider\n# from advanced_tsp_solver import AdvancedTSPSolver\n# from Three_PointO_ArchE.llm_providers.base import BaseLLMProvider\n\nlogger = logging.getLogger(__name__)\n\nclass StrategicWorkflowPlanner:\n    \"\"\"\n    Translates a complex natural language query into an optimized workflow\n    by leveraging a combinatorial optimization solver.\n    \"\"\"\n\n    def __init__(self, llm_provider: Any, solver: Any):\n        \"\"\"\n        Initializes the planner with a language model and a solver.\n\n        Args:\n            llm_provider: An instance of a large language model provider.\n            solver: An instance of the AdvancedTSPSolver.\n        \"\"\"\n        self.llm = llm_provider\n        self.solver = solver\n        self.action_registry = main_action_registry\n        logger.info(\"StrategicWorkflowPlanner initialized.\")\n\n    def deconstruct_blueprint(self, blueprint_query: str) -> Dict[str, Any]:\n        \"\"\"\n        Uses an LLM to deconstruct a complex query into a sequence of executable actions.\n        \"\"\"\n        logger.info(f\"Deconstructing blueprint: {blueprint_query[:100]}...\")\n\n        action_signatures = self.action_registry.get_action_signatures()\n\n        prompt = f\"\"\"\n        You are an expert system architect. Your task is to analyze a user's request and deconstruct it into a sequence of executable tasks for the ArchE system.\n        You must only use the actions available in the provided \"Action API Reference\". Pay close attention to the required parameters for each action.\n\n        **User Request:**\n        \"{blueprint_query}\"\n\n        **Action API Reference:**\n        ```json\n        {json.dumps(action_signatures, indent=2)}\n        ```\n\n        **CRITICAL INSTRUCTION:** The `inputs` for each task MUST be a flat JSON object where the keys are the parameter names from the 'params' section of the Action API Reference. DO NOT nest the inputs inside another `inputs` or `kwargs` key.\n\n        **Instructions:**\n        1.  Carefully read the User Request to understand the overall goal.\n        2.  Identify the sequence of steps required to fulfill the request.\n        3.  For each step, select the most appropriate action from the \"Action API Reference\".\n        4.  **PRIORITY: Use federated agents for web searches and research tasks:**\n           - For web searches, use `invoke_specialist_agent` with `agent_type: \"search\"` or `agent_type: \"academic\"`\n           - For YouTube video analysis, use `invoke_specialist_agent` with `agent_type: \"visual\"`\n           - For community/social research, use `invoke_specialist_agent` with `agent_type: \"community\"`\n        5.  Construct the `inputs` for each action precisely as defined in its `params`.\n        6.  Values for inputs can be static (from the query) or dynamic, referencing outputs from previous tasks using the format `{{{{TASK_ID.output.key}}}}`.\n        7.  Provide a concise, human-readable `description` for each task.\n        8.  Define the `dependencies` between tasks. A task can only depend on tasks that come before it in the execution plan.\n        9.  Return a single JSON object containing the `tasks` and `dependencies`.\n\n        **Example Output Format:**\n        {{\n            \"tasks\": {{\n                \"TASK_1_WEB_SEARCH\": {{\n                    \"description\": \"Search for latest developments using federated search agents\",\n                    \"action_type\": \"invoke_specialist_agent\",\n                    \"inputs\": {{\n                        \"agent_type\": \"search\",\n                        \"query\": \"latest developments in quantum computing\",\n                        \"max_results\": 5\n                    }}\n                }},\n                \"TASK_2_YOUTUBE_ANALYSIS\": {{\n                    \"description\": \"Analyze YouTube videos about quantum supremacy using visual synthesis agent\",\n                    \"action_type\": \"invoke_specialist_agent\",\n                    \"inputs\": {{\n                        \"agent_type\": \"visual\",\n                        \"query\": \"quantum supremacy breakthroughs\",\n                        \"max_results\": 3\n                    }}\n                }},\n                \"TASK_3_SYNTHESIS\": {{\n                    \"description\": \"Synthesize findings from web search and video analysis\",\n                    \"action_type\": \"generate_text_llm\",\n                    \"inputs\": {{\n                        \"prompt\": \"Based on the web search results: {{{{TASK_1_WEB_SEARCH.output}}}} and YouTube analysis: {{{{TASK_2_YOUTUBE_ANALYSIS.output}}}}, provide a comprehensive analysis of quantum computing developments.\"\n                    }}\n                }}\n            }},\n            \"dependencies\": {{\n                \"TASK_2_YOUTUBE_ANALYSIS\": [\"TASK_1_WEB_SEARCH\"],\n                \"TASK_3_SYNTHESIS\": [\"TASK_1_WEB_SEARCH\", \"TASK_2_YOUTUBE_ANALYSIS\"]\n            }}\n        }}\n\n        **Begin Deconstruction:**\n        \"\"\"\n\n        try:\n            response = self.llm.generate(prompt=prompt, model=\"gemini-2.0-flash-exp\")\n            # The response from the LLM is expected to be a JSON string.\n            # It might be wrapped in markdown ```json ... ```, so we need to clean it.\n            cleaned_response = response.strip().strip(\"`\").strip()\n            if cleaned_response.startswith(\"json\"):\n                cleaned_response = cleaned_response[4:].strip()\n            \n            deconstructed_plan = json.loads(cleaned_response)\n            logger.info(\"Blueprint deconstructed successfully by LLM.\")\n            return deconstructed_plan\n        except (json.JSONDecodeError, TypeError) as e:\n            logger.error(f\"Failed to deconstruct blueprint. LLM output was not valid JSON: {e}\")\n            # Fallback to a safe, empty plan\n            return {\"tasks\": {}, \"dependencies\": {}}\n        except Exception as e:\n            logger.error(f\"An unexpected error occurred during blueprint deconstruction: {e}\")\n            return {\"tasks\": {}, \"dependencies\": {}}\n\n\n    def formulate_optimization_problem(self, deconstruction: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Formulates the deconstructed goals into a formal problem for the solver.\n        (This is a placeholder).\n        \"\"\"\n        logger.info(\"Formulating optimization problem...\")\n        # This would involve mapping goals to actions, estimating costs, etc.\n        placeholder_problem = {\n            # This structure needs to match the input of the AdvancedTSPSolver\n            \"locations\": [\"Depot\"] + list(deconstruction.get(\"tasks\", {}).keys()),\n            \"num_vehicles\": 1,\n            \"depot\": 0\n            # ... plus distance/cost matrices, constraints, etc.\n        }\n        logger.info(\"Optimization problem formulated.\")\n        return placeholder_problem\n\n    def translate_solution_to_workflow(self, deconstruction: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Translates the deconstructed and potentially optimized plan into a full ArchE workflow.\n        \"\"\"\n        logger.info(\"Translating deconstructed plan to an executable workflow...\")\n        \n        # For now, we are skipping the optimization step and using the direct deconstruction.\n        workflow = {\n            \"name\": \"Strategically_Generated_Workflow\",\n            \"description\": \"This workflow was dynamically generated by the StrategicWorkflowPlanner.\",\n            \"tasks\": deconstruction.get(\"tasks\", {}),\n            \"dependencies\": deconstruction.get(\"dependencies\", {})\n        }\n        \n        logger.info(\"Workflow translated successfully.\")\n        return workflow\n\n    def generate_workflow_from_blueprint(self, blueprint_query: str) -> Dict[str, Any]:\n        \"\"\"\n        The main entry point that orchestrates the entire translation process.\n        \"\"\"\n        logger.info(\"Starting strategic workflow generation from blueprint.\")\n        \n        # Step 1: Deconstruct the query into executable tasks\n        deconstruction = self.deconstruct_blueprint(blueprint_query)\n        \n        # Save the deconstruction blueprint to outputs directory\n        try:\n            from pathlib import Path\n            import time\n            \n            outputs_dir = Path(\"outputs\")\n            outputs_dir.mkdir(exist_ok=True)\n            \n            timestamp = int(time.time())\n            blueprint_filename = f\"blueprint_deconstruction_{timestamp}.json\"\n            blueprint_filepath = outputs_dir / blueprint_filename\n            \n            blueprint_data = {\n                \"original_query\": blueprint_query,\n                \"deconstruction\": deconstruction,\n                \"timestamp\": timestamp\n            }\n            \n            with open(blueprint_filepath, 'w', encoding='utf-8') as f:\n                json.dump(blueprint_data, f, indent=2)\n            logger.info(f\"Blueprint deconstruction saved to: {blueprint_filepath}\")\n        except Exception as e:\n            logger.warning(f\"Failed to save blueprint deconstruction: {e}\")\n        \n        if not deconstruction or not deconstruction.get(\"tasks\"):\n            logger.warning(\"Deconstruction resulted in an empty plan. Aborting workflow generation.\")\n            return {\n                \"name\": \"Empty_Workflow\",\n                \"description\": \"Workflow generation failed because the blueprint could not be deconstructed into actions.\",\n                \"tasks\": {},\n                \"dependencies\": {}\n            }\n\n        # Step 2: Formulate the problem for the solver (currently a placeholder)\n        # optimization_problem = self.formulate_optimization_problem(deconstruction)\n        \n        # Step 3: Invoke the solver (conceptual)\n        # For now, we will just use the sequence from the deconstruction.\n        # solver_solution = {\"route\": list(deconstruction.get(\"tasks\", {}).keys())} # Placeholder\n        # logger.info(f\"Solver found optimal path: {solver_solution['route']}\")\n        \n        # Step 4: Translate the deconstruction back to a workflow\n        executable_workflow = self.translate_solution_to_workflow(deconstruction)\n        \n        logger.info(\"Strategic workflow generation complete.\")\n        return executable_workflow\n\n# Example usage:\nif __name__ == '__main__':\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n    \n    # Mock LLM and Solver for demonstration\n    class MockLLM:\n        def generate_text(self, prompt: str, model: str) -> str:\n            # Simulate a simple LLM response for demonstration\n            if \"Forge the CognitiveOperationalBridgE\" in prompt:\n                return json.dumps({\n                    \"tasks\": {\n                        \"A\": {\"action_type\": \"create_universal_ledger\", \"inputs\": {}},\n                        \"B\": {\"action_type\": \"refactor_logger\", \"inputs\": {}},\n                        \"C\": {\"action_type\": \"integrate_scribe_actions\", \"inputs\": {}}\n                    },\n                    \"dependencies\": {\n                        \"B\": [\"A\"],\n                        \"C\": [\"A\"]\n                    }\n                })\n            elif \"Establish a universal ledger\" in prompt:\n                return json.dumps({\n                    \"tasks\": {\n                        \"A\": {\"action_type\": \"create_universal_ledger\", \"inputs\": {}},\n                        \"B\": {\"action_type\": \"refactor_logger\", \"inputs\": {}},\n                        \"C\": {\"action_type\": \"integrate_scribe_actions\", \"inputs\": {}}\n                    },\n                    \"dependencies\": {\n                        \"B\": [\"A\"],\n                        \"C\": [\"A\"]\n                    }\n                })\n            else:\n                return json.dumps({\n                    \"tasks\": {\n                        \"A\": {\"action_type\": \"create_universal_ledger\", \"inputs\": {}},\n                        \"B\": {\"action_type\": \"refactor_logger\", \"inputs\": {}},\n                        \"C\": {\"action_type\": \"integrate_scribe_actions\", \"inputs\": {}}\n                    },\n                    \"dependencies\": {\n                        \"B\": [\"A\"],\n                        \"C\": [\"A\"]\n                    }\n                })\n\n    class MockSolver:\n        pass\n        \n    planner = StrategicWorkflowPlanner(llm_provider=MockLLM(), solver=MockSolver())\n    \n    blueprint = \"Forge the CognitiveOperationalBridgE by first creating a Universal Ledger, then refactoring the system to use it, and finally integrating the Scribe's actions.\"\n    \n    final_workflow = planner.generate_workflow_from_blueprint(blueprint)\n    \n    print(\"\\n--- Generated Workflow ---\")\n    print(json.dumps(final_workflow, indent=2))\n    print(\"------------------------\")\n\n\n\n```\n\nEXAMPLE APPLICATION:\nClass: MockLLM\n\nMethods: generate_text\n\nCATEGORY: CodeKnowledge\n\nRELATIONSHIPS:\ntype: FromCodebase; source: /mnt/3626C55326C514B1/Happier/Three_PointO_ArchE/strategic_workflow_planner.py; source_type: python_class"}